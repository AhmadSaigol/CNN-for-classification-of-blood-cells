{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Training_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tLibka2Gg6XX",
        "fRAc81N3nqVk",
        "u0Xsdzy0mC4L",
        "J7MbemEy0CEI",
        "tOe2csdknYrH",
        "10dKfcgy4EMG",
        "rdkSkOQVx7mO",
        "_9YgsjMlnw9F",
        "7aGfdexdtt_R",
        "p0dxfEEMZCK7",
        "P-E-FLloLdji",
        "9YH9YIxALi7K",
        "b9QkF0dhMmMw",
        "RYqBXweoJuDB",
        "uGwpY1s4JyQ2",
        "tEMnVZculKvb",
        "VxwRge3jlMrL",
        "A7LGrCn1lSQ6",
        "soGwab7ZlUBl",
        "ponrpRBqlYub",
        "n-pkhmTouZmq",
        "A9v0HE4z1rts",
        "p7nTLFEdTG0h",
        "1cqVvuqInexL",
        "mxoYcLNU44mG",
        "t6G1mINc7M5L",
        "FJqOZ3Ot19Ve",
        "Zu_js9RU2KZ4",
        "FEp5_qqCBDjR",
        "Mk6zauR5FEXs",
        "u0GtJkLj2b0K",
        "nDtOcxKb23Rf",
        "DL_repyo285r",
        "MqBC-AU72_79"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLibka2Gg6XX"
      },
      "source": [
        "# Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8NABrydkX4I"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image as pilimg\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU0qDkILn82C"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7BhAm6Gn8gm"
      },
      "source": [
        "class Dataset:\n",
        "  '''\n",
        "    Returns an object of \"Dataset\" class that is used as input to 'Network' class.\n",
        "\n",
        "    Paramters:\n",
        "\n",
        "      'path' : str \n",
        "        path to main folder containing subfolders of images in a specific structure. For more info, see notes.\n",
        "      \n",
        "      'resize' : tuple of ints (width, height) (optional)\n",
        "        shape of image in which it would be resized to. If no value is passed, no resizing will be done.\n",
        "\n",
        "      'split_ratio' : tuple of int or float (train_size_percent, valid_size_percent, test_size_percent) Default = (60,20,20) (optional)\n",
        "        ratio in which data will be split. The sum of the values must be equal to 100. \n",
        "\n",
        "      'zero_center': str = 'per_channel' or 'image'. Default = None (optional)\n",
        "        defines zero centering of the data. It can take one of the folllowing values:\n",
        "\n",
        "            'per_channel' : Subtract the mean per channel calculated over all images (like in VGG)\n",
        "            'image' : Subtract mean image calculated over all images (like in AlexNet)\n",
        "\n",
        "        If no value is passed, zero centering of the data will not be done\n",
        "\n",
        "    Notes:\n",
        "\n",
        "      - The class expects images to be in certain architecture of folders. There should be one main folder whose path will be passed\n",
        "        to the parameter 'path'. Inside this main folder, there should be, equal to number of classes, folders. Each folder should be named\n",
        "        with class label and inside it, there should be only images (in jpeg format, each having same size with shape(W,H,3)) of this class.\n",
        "        Make sure there are no hidden folders.Everything else except folders and images will be ignored. \n",
        "    \n",
        "      - The class expects images to be in uint8 format as it will map these values between 0 and 1 for better processing. \n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self, path, resize = None, split_ratio = (60,20,20), zero_center = None):\n",
        " \n",
        "\n",
        "    #check whether correct value for 'path' is provided\n",
        "\n",
        "    if not os.path.isdir(path):\n",
        "      sys.exit(\"Invalid Path provided. The path must be a valid directory\")\n",
        "\n",
        "    #store labels\n",
        "    self.labels = [label for label in os.listdir(path) if os.path.isdir(os.path.join(path, label)) and not label.startswith('.') ]\n",
        "    self.labels.sort()\n",
        "    \n",
        "\n",
        "    if len(self.labels) == 0:\n",
        "      sys.exit(\"The directory provided is either empty or does not follow the specified architecture of folders. For more info, see the documentation of class 'Dataset'\")\n",
        "    else:\n",
        "\n",
        "      data =list()\n",
        "\n",
        "      for index,label in enumerate(self.labels):\n",
        "      \n",
        "        for image in os.listdir(os.path.join(path, label)):\n",
        "\n",
        "          if image.endswith(\".jpg\"):\n",
        "             \n",
        "              #store path to images and annotate it with labels\n",
        "              data.append([os.path.join(path, label, image), index])\n",
        "          \n",
        "\n",
        "    if len(data) == 0:\n",
        "      sys.exit(\"The directories inside the specified folder are either empty or does not have images in jpg.\")\n",
        "    \n",
        "\n",
        "    print(\"Total \", len(data), \" images found with total \", len(self.labels), \" classes\")\n",
        "    print('labels', self.labels)\n",
        "    \n",
        "    #Resize \n",
        "    if resize != None and len(resize) != 2:\n",
        "        sys.exit(\"Parameter 'resize' can only take two integers as tuple\")\n",
        "      \n",
        "    self.resize = resize\n",
        "\n",
        "    #Splits the dataset\n",
        "    if len(split_ratio) != 3:\n",
        "      sys.exit(\"Invalid Values provided for parameter 'split_ratio'. It can take can only three values as tuple (train, valid, test)\")\n",
        "    \n",
        "    elif np.sum(split_ratio) != 100:\n",
        "      sys.exit(\"Invalid Values provided for parameter 'split_ratio'. train, valid and test must add up to 100.\")\n",
        "    \n",
        "    else:\n",
        "      self.train_data, self.valid_data, self.test_data = self.SplitData(data, split_ratio)\n",
        "\n",
        "    #Calculate values for zero centering of the data\n",
        "    if zero_center == None:\n",
        "      self.mean = 0\n",
        "    elif zero_center == 'per_channel':\n",
        "      self.mean = self.PerChannelMean()\n",
        "    elif zero_center == 'image':\n",
        "      self.mean = self.MeanImage()\n",
        "    else:\n",
        "      sys.exit(\"Invalid Value Provided for parameter 'zero_center'. It can only take None, 'per_channel' or 'image'. \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def SplitData(self, data, split_ratio):\n",
        "    '''\n",
        "    Splits the dataset and returns training, validation and test dataset, each as tuple of (data, labels):\n",
        "    \n",
        "    Parameters:\n",
        "\n",
        "    data: list of shape (total_images, 2) with 'path to image' in its first axis and 'label' in the second axis\n",
        "      Dataset which needs to be split.\n",
        "    \n",
        "    'split_ratio' : tuple of int or float (train_size_percent, valid_size_percent, test_size_percent)\n",
        "          ratio in which data will be split. The sum of the values must be equal to 100. \n",
        "    \n",
        "    '''\n",
        "    #Shuffle data    \n",
        "    np.random.shuffle(data)\n",
        "    \n",
        "    #Split data\n",
        "    train_data, valid_data, test_data = np.split(data, [int((split_ratio[0]/100)*len(data)), int(((split_ratio[0]+split_ratio[1])/100)*len(data))])\n",
        "      \n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "    \n",
        "    \n",
        "  def PerChannelMean(self):\n",
        "    '''\n",
        "    Calculates and returns mean of each channel over training dataset as array of size 3 [R,G,B] :\n",
        "\n",
        "    Notes:\n",
        "\n",
        "      -  It expects image to be in RBG format with shape (width, height, 3)\n",
        "\n",
        "    '''\n",
        "    \n",
        "    sum=np.array([0.0])\n",
        "    \n",
        "    for img, _ in self.train_data:\n",
        "\n",
        "      #Read image\n",
        "      img = pilimg.open(img)\n",
        "\n",
        "      #Resize image\n",
        "      if self.resize != None:      \n",
        "        img =img.resize(self.resize)\n",
        "       \n",
        "      img = np.asarray(img)\n",
        "\n",
        "      #map image between 0 and 1\n",
        "      img  = img / 255\n",
        "\n",
        "      #accumulate values\n",
        "      sum = sum + img\n",
        "\n",
        "    #return mean along three channels\n",
        "    return np.sum(sum, axis=(0,1), keepdims=True)/(self.train_data.shape[0]*sum.shape[0]*sum.shape[1])\n",
        "  \n",
        "  \n",
        "  def MeanImage(self):\n",
        "    '''\n",
        "    Calculates and returns mean image over training dataset as array of shape (M,N,3).\n",
        "\n",
        "    Notes:\n",
        "\n",
        "     -  It expects image to be in RBG format with shape (width, height, 3)\n",
        "\n",
        "    '''\n",
        "    sum=np.array([0.0])\n",
        "\n",
        "    for img, _ in self.train_data:\n",
        "      \n",
        "      #Read image\n",
        "      img = pilimg.open(img)\n",
        "\n",
        "      #Resize image\n",
        "      if self.resize != None:\n",
        "        img =img.resize(self.resize)\n",
        "       \n",
        "      img = np.asarray(img)\n",
        "\n",
        "      #map image between 0 and 1\n",
        "      img = img / 255\n",
        "      \n",
        "      #accumulate values\n",
        "      sum = sum + img\n",
        "\n",
        "    #return mean image\n",
        "    return sum/self.train_data.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  def load_data(self, flag, batch):\n",
        "    '''\n",
        "    loads and returns a batch of images with labels of the specified dataset.\n",
        "    The output returns two things:\n",
        "        \n",
        "        imgBatch: numpy array of images of shape ( batch, channels, rows, cols ):\n",
        "        labelBatch: numpy array of labels of shape (batch, 1) \n",
        "        \n",
        "    Parameters:\n",
        "\n",
        "      'flag' : str = 'train', 'valid', or 'test'\n",
        "        Specifies from which dataset to load the images\n",
        "\n",
        "      'batch': list of integers [start, end]\n",
        "        loads images from dataset with the specified indexes as start (inclusive) and end (not inclusive)\n",
        "    \n",
        "    '''\n",
        "    #load path of images from the corresponding dataset\n",
        "\n",
        "    if flag == 'train':\n",
        "      files = self.train_data[batch[0] : batch[1]]\n",
        "    elif flag == 'valid':\n",
        "      files = self.valid_data[batch[0] : batch[1]]\n",
        "    elif flag == 'test':\n",
        "      files =self.test_data[batch[0] : batch[1]]\n",
        "    else:\n",
        "      sys.exit(\"Invalid value provided for parameter 'flag'. It can either be 'train', 'valid' or 'test'\")\n",
        "    \n",
        "\n",
        "    #build batch of images and labels\n",
        "    for index, data in enumerate(files):\n",
        "      \n",
        "      #Read image\n",
        "      img = pilimg.open(data[0])\n",
        "\n",
        "      #Resize image\n",
        "      if self.resize != None:\n",
        "        img =img.resize(self.resize)\n",
        "       \n",
        "      img = np.asarray(img)\n",
        "      \n",
        "      #map image between 0 and 1\n",
        "      img  = img / 255\n",
        "\n",
        "      #zero center the data\n",
        "      img = img - self.mean      \n",
        "      \n",
        "      #reshape image to (depth, width, height)\n",
        "      img = np.array([img[:,:,0],img[:,:,1],img[:,:,2]])\n",
        "      \n",
        "\n",
        "      #for creating batch of images\n",
        "      if index == 0:\n",
        "        imgBatch = np.zeros([len(files), img.shape[0], img.shape[1], img.shape[2]] )\n",
        "\n",
        "        #by filling with value more than total number of labels, it makes sure\n",
        "        #that all values are replaced with proper label (as this will be checked by loss fnt in case improper value is passed)\n",
        "        labelBatch = np.full((len(files), 1) , fill_value = len(self.labels)+1 )\n",
        "        \n",
        "      imgBatch[index] = img\n",
        "\n",
        "      labelBatch[index] = data[1]\n",
        "\n",
        "      \n",
        "    return imgBatch, labelBatch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRAc81N3nqVk"
      },
      "source": [
        "# Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leznOidhn7vp"
      },
      "source": [
        "class Conv:\n",
        "  '''\n",
        "    Returns an object of \"Conv\" class that is used as Convolution Layer in CNNs.\n",
        "\n",
        "    Paramters:\n",
        "\n",
        "        'number_of_filters' : non-zero, positive, int \n",
        "          Number of filters that will be convolved with the activation maps\n",
        "        \n",
        "        'filter_size' : non-zero, positive, odd, int \n",
        "          size of the square filter\n",
        "        \n",
        "        'stride' : non-zero, positive, int. Default=1 (optional)\n",
        "          size of step to take in horizontal and vertical direction\n",
        "\n",
        "        'zero_padding' : positive, int. Default=0 (i.e. no zero padding) (optional)\n",
        "          number of rows and columns of zeros that need to be added around the activation maps.\n",
        "            For example, if it is specified to be as 2 and activations has a shape of (batch, channels, rows, cols), then \n",
        "            after zero padding, the new shape of activations will be (batch, channels, rows + 4, cols + 4) with zeros above and below, right and left of the axis -1 and -2.\n",
        "\n",
        "    \n",
        "    Notes:\n",
        "    \n",
        "      -   Combination of stride, zero padding, last two axis of both filters and activation maps must be \n",
        "          such that it results an whole number for the following equation:\n",
        "\n",
        "                 For each axis: \n",
        "                         O = ( ( R - F + 2P ) / S ) + 1 \n",
        "                 where\n",
        "                         O = size of output axis\n",
        "                         R = size of activation map axis\n",
        "                         F = size of filter\n",
        "                         P = amount of zero padding\n",
        "                         S = stride\n",
        "    \n",
        "  '''\n",
        "  \n",
        "  def __init__(self, number_of_filters, filter_size, stride=1, zero_padding=0 ):\n",
        "\n",
        "    \n",
        "    #Check whether valid values are provided for paramters and store accordingly\n",
        "\n",
        "    if number_of_filters <= 0 or number_of_filters % 1 != 0: \n",
        "      sys.exit(\"Invalid Value provided for parameter 'number_of_filters'. It must be non-zero, positive integer.\")\n",
        "    else:\n",
        "      self.number_of_filters =number_of_filters\n",
        "\n",
        "    if filter_size <= 0 or filter_size % 1 != 0 or filter_size % 2 == 0: \n",
        "      sys.exit(\"Invalid Value provided for parameter 'filter_size'. It must be non-zero, positive, odd integer\")\n",
        "    else:\n",
        "      self.filter_size=filter_size\n",
        "    \n",
        "    if stride <= 0 or stride % 1 !=0:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'stride'.It must be non-zero, positive integer.\")\n",
        "    else:\n",
        "      self.stride = stride\n",
        "    \n",
        "    if zero_padding < 0 or zero_padding  % 1 !=0:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'zero_padding'. It must be positive integer.\")\n",
        "    else:\n",
        "      self.zero_padding=zero_padding\n",
        "\n",
        "    # Variables associated with this layer\n",
        "    self.weights=np.array([])\n",
        "    self.dW=np.array([])\n",
        "\n",
        "    self.bias=np.array([])\n",
        "    self.dB=np.array([])\n",
        "\n",
        "    self.inputs = np.array([])\n",
        "\n",
        "    \n",
        "\n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Performs Convolution of each filter with each image and returns the result with shape = (b, d, r, c):\n",
        "\n",
        "          b = batch (same as 'activations')\n",
        "          d = channels (same as 'number of filters')\n",
        "          r, c = Rows and Columns (calculated using the formula described in the constructor of the class) \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'activations' : numpy array of shape (batch, channels, rows, columns)\n",
        "          Activation maps which will be convolved with filters\n",
        "\n",
        "        'train' : bool. Default=False (optional)\n",
        "          whether training of the layer is being carried out or not \n",
        "    '''\n",
        "\n",
        "    if self.weights.shape[0] != self.number_of_filters: \n",
        "      sys.exit(\"Error in number of filters. Number of filters with weights do not match with number of filters specified\") \n",
        "\n",
        "    if self.bias.shape[0] != self.number_of_filters:\n",
        "      sys.exit(\"Error in number of filters. Number of filters with  bias do not match with number of filters specified\") \n",
        "\n",
        "    if activations.shape[1] != self.weights.shape[1]:\n",
        "      sys.exit(\"Depth of activations do not match with depth of filters. Check the channels of activation map and filters\") \n",
        "    \n",
        "    if self.bias.shape[1] != 1:\n",
        "        sys.exit(\"Invalid Shape of parameter 'bias'. It must be of shape (number_of_filters,1)\")\n",
        "    \n",
        "    if activations.shape[-1] != activations.shape[-2]:\n",
        "        sys.exit(\"The rows and columns (i.e axis =-1 and -2) of Activations must be same for convolution. \")\n",
        "\n",
        "    if train:\n",
        "      self.inputs = activations\n",
        "\n",
        "    #Apply Zero padding\n",
        "  \n",
        "    pw=[[0,0]]*(np.size(activations.shape)-2) + [[self.zero_padding, self.zero_padding]]*2 #list of pad widths for each axis\n",
        "    activations = np.pad(activations, pw, 'constant', constant_values=0)\n",
        "\n",
        "    #Convolution\n",
        "    output_row_col = ((np.array(activations.shape[-2:]) - self.weights.shape[-2:])/self.stride)+1\n",
        "    \n",
        "    #check whether filter and activations convolve properly\n",
        "    if any(output_row_col%1 !=0) :\n",
        "      print('Properties at this layer:')\n",
        "      print('\\t Layer type = Convolution')\n",
        "      print('\\t Size of Activations (with zero padding) = ', activations.shape )\n",
        "      print('\\t\\t\\t ( Batch, Channels, Rows, Columns )')\n",
        "      print('\\t Size of Filters = ', self.weights.shape )\n",
        "      print('\\t\\t\\t ( Number of Filters, Channels, Rows, Columns )')\n",
        "      print('\\t Padding = ',  self.zero_padding )\n",
        "      print('\\t Stride = ' , self.stride )\n",
        "      \n",
        "      sys.exit('Undefined Values at Boundary of Activation Map: '\\\n",
        "               'Combination of stride, zero padding, last two axis (axis=-1,-2) of both filters and activation maps is not correct.'\\\n",
        "               'Properties at this layer are printed above. For more, see the documentation of \"Conv\" class')\n",
        "\n",
        "    \n",
        "    #array of zeros for output of convolution operation\n",
        "    output=np.zeros((activations.shape[0], self.weights.shape[0]) + tuple(output_row_col.astype(np.int)))\n",
        "    \n",
        "    if train:\n",
        "      self.output_shape=output.shape\n",
        "\n",
        "    for filter in range(self.number_of_filters):\n",
        "\n",
        "      for rows in range(output.shape[-2]):\n",
        "\n",
        "        for cols in range(output.shape[-1]):\n",
        "          \n",
        "          #adusting values with stride\n",
        "          r=rows*self.stride\n",
        "          c=cols*self.stride\n",
        "          \n",
        "          #extract part of image, perform convolution and assign it to new map\n",
        "          output[:,filter, rows, cols]=np.sum(activations[:,:, r:r + self.weights.shape[-2] , c:c + self.weights.shape[-1]] * self.weights[filter,:,:,:], axis=(1,2,3)) + self.bias[filter]\n",
        "    \n",
        "    return output\n",
        "\n",
        "  def backward(self, dL):\n",
        "    '''\n",
        "      Calculates gradients with respect to inputs, weights and bias of this layer\n",
        "      and returns gradient w.r.t input of shape (same as input to this layer):\n",
        "          \n",
        "      Parameters:\n",
        "\n",
        "        'dL' : numpy array of shape (same as output of this layer)\n",
        "          Global gradient flowing from the next layer\n",
        "\n",
        "    '''\n",
        "\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the Convlutional layer\")   \n",
        "\n",
        "    #gradient w.r.t bias\n",
        "    self.dB = np.sum(dL, axis=(0,2,3)).reshape(-1,1)\n",
        "\n",
        "    #gradient w.r.t weights\n",
        "\n",
        "    #apply zero padding to inputs of the layer\n",
        "    pw=[[0,0]]*(np.size(self.inputs.shape)-2) + [[self.zero_padding, self.zero_padding]]*2\n",
        "    X = np.pad(self.inputs, pw, 'constant', constant_values=0)\n",
        "\n",
        "    self.dW = np.zeros(self.weights.shape)\n",
        "\n",
        "    #Valid Convolution (X,dL)\n",
        "    for filter in range(self.number_of_filters):\n",
        "\n",
        "      for rows in range(self.weights.shape[-2]):\n",
        "\n",
        "        for cols in range(self.weights.shape[-1]):\n",
        "        \n",
        "          #adusting values with stride\n",
        "          r=rows*self.stride\n",
        "          c=cols*self.stride\n",
        "          \n",
        "          #concentenate dL to match depth of weights\n",
        "          temp=np.concatenate( [dL[:,filter, np.newaxis, :,:]] * X.shape[1],  axis=1)\n",
        "\n",
        "          #dW\n",
        "          self.dW[filter, :, rows, cols]= np.sum(temp*X[:,:, r:r + dL.shape[-2] , c:c + dL.shape[-1]], axis=(0,2,3))\n",
        "\n",
        "    #gradient w.r.t inputs\n",
        "\n",
        "    #apply zero padding to weights of the layer\n",
        "    pw=[[0,0]]*(np.size(self.weights.shape)-2) + [[dL.shape[-1]-1,dL.shape[-1]-1]]*2\n",
        "    W = np.pad(self.weights, pw, 'constant', constant_values=0)\n",
        "\n",
        "    #calculate shape of dX\n",
        "    output_row_col = ((np.array(W.shape[-2:]) - dL.shape[-2:]) / self.stride) +1\n",
        "    dX = np.zeros((dL.shape[0], self.weights.shape[1]) + tuple(output_row_col.astype(np.int)))\n",
        "\n",
        "    #flip the weights\n",
        "    W=np.flip(W, axis=(-1,-2))\n",
        "\n",
        "    #Full Convlution (rotated weights, dL)\n",
        "    for filter in range(self.number_of_filters):\n",
        "\n",
        "        for rows in range(dX.shape[-2]):\n",
        "\n",
        "          for cols in range(dX.shape[-1]):\n",
        "          \n",
        "            #adusting values with stride\n",
        "            r=rows*self.stride\n",
        "            c=cols*self.stride\n",
        "\n",
        "            #concentenate dL to match depth of weights\n",
        "            temp=np.concatenate([dL[:,filter, np.newaxis,:,:]]*W.shape[1], axis=1)\n",
        "\n",
        "            #dX\n",
        "            dX[:, :, rows, cols] += np.sum(temp*W[filter,:, r:r + dL.shape[-2] , c:c + dL.shape[-1]], axis=(2,3))\n",
        "\n",
        "\n",
        "    #Flip the result \n",
        "    dX=np.flip(dX, axis=(-1,-2)) \n",
        "\n",
        "    #remove zero padding and return dX\n",
        "    return dX[:,:, self.zero_padding:dX.shape[-2]-self.zero_padding, self.zero_padding:dX.shape[-1]-self.zero_padding]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0Xsdzy0mC4L"
      },
      "source": [
        "# Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7MbemEy0CEI"
      },
      "source": [
        "## Hyperbolic Tangent Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIDN4cYT0O_m"
      },
      "source": [
        "class Tanh:\n",
        "  '''\n",
        "    Returns an object of class \"Tanh\" that can be used as activation function in CNNs\n",
        "  \n",
        "  '''\n",
        "  \n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Applies Hyperbolic Tangent function to the input and returns the result\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'activations' : numpy array\n",
        "          activations on which tanh function will be applied\n",
        "        \n",
        "        'train' : bool. Default=False\n",
        "          whether training of the layer is being carried out or not \n",
        "    '''\n",
        "\n",
        "    #apply tanh funciton\n",
        "    output = np.tanh(activations)\n",
        "\n",
        "    # calculate local gradient\n",
        "    if train:\n",
        "      self.output_shape = output.shape\n",
        "      self.dT = 1-np.square(output)\n",
        "    \n",
        "    return output\n",
        "\n",
        " \n",
        "  def backward (self, dL):\n",
        "    '''\n",
        "      Calculates and returns gradient with respect to inputs to this layer\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'dL' : numpy array of shape (same as output of this layer) \n",
        "          global gradient (flowing from the next layer)\n",
        "  \n",
        "    '''\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the tanh layer\") \n",
        "    \n",
        "    #dX\n",
        "    return dL*self.dT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOe2csdknYrH"
      },
      "source": [
        "## ReLU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEBkdHKInffj"
      },
      "source": [
        "class ReLU:\n",
        "  '''\n",
        "    Returns an object of \"ReLU\" class that can be used as activation function in CNNs\n",
        "  \n",
        "  '''\n",
        "\n",
        "\n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Applies ReLU function to the input and returns the result\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'activations' : numpy array\n",
        "          activations on which ReLU function will be applied\n",
        "        \n",
        "        'train' : bool. Default=False\n",
        "          whether training of the layer is being carried out or not \n",
        "    '''\n",
        "\n",
        "    #apply ReLU\n",
        "    output = np.maximum(0, activations)\n",
        "\n",
        "    #calculate local gradient\n",
        "    if train:\n",
        "      self.output_shape = output.shape\n",
        "      self.dR =  1 * (activations > 0)\n",
        "\n",
        "    return output \n",
        "\n",
        "\n",
        "  def backward (self, dL):\n",
        "    '''\n",
        "      Calculates and returns gradient with respect to inputs to this layer\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'dL' : numpy array of shape (same as output of this layer) \n",
        "          global gradient (flowing from the next layer)\n",
        "  \n",
        "    '''\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the ReLU layer\") \n",
        "    \n",
        "    #dX\n",
        "    return dL*(self.dR)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10dKfcgy4EMG"
      },
      "source": [
        "## Leaky ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udg-5frc4JCl"
      },
      "source": [
        "class LeakyReLU:\n",
        "  '''\n",
        "    Returns an object of \"LeakyRelU\" class that can be used as activation function in CNNs\n",
        "\n",
        "    Parameters:\n",
        "      \n",
        "      'slope' : int or float. Default=0.01 (optional)\n",
        "        slope of the function for negative values of input i.e it represents 'a' in the following formula:\n",
        "\n",
        "            f(x) = max(ax, x)\n",
        "  \n",
        "  '''\n",
        "  def __init__(self, slope=0.01):\n",
        "    \n",
        "      self.slope = slope\n",
        "\n",
        "\n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Applies LeakyReLU function to the input and returns the result\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'activations' : numpy array\n",
        "          activations on which LeakyReLU function will be applied\n",
        "        \n",
        "        'train' : bool. Default=False\n",
        "          whether training of the layer is being carried out or not \n",
        "    '''\n",
        "\n",
        "    #apply LeakyReLU\n",
        "    output = np.maximum(self.slope*activations, activations)\n",
        "\n",
        "    #calculate local gradient\n",
        "    if train:\n",
        "      self.output_shape = output.shape\n",
        "      self.dLR =  np.ones(activations.shape)\n",
        "      self.dLR [activations < 0] = self.slope\n",
        "\n",
        "    return output \n",
        "\n",
        "\n",
        "  def backward (self, dL):\n",
        "    '''\n",
        "      Calculates and returns gradient with respect to inputs to this layer\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'dL' : numpy array of shape (same as output of this layer) \n",
        "          global gradient (flowing from the next layer)\n",
        "  \n",
        "    '''\n",
        "\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the LeakyReLU layer\") \n",
        "\n",
        "    #dX\n",
        "    return dL*(self.dLR)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdkSkOQVx7mO"
      },
      "source": [
        "## Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5_CTGdgx7mO"
      },
      "source": [
        "class Softmax:\n",
        "  '''\n",
        "    Returns an object of \"Softmax\" class that can be used with cross entropy loss in CNNs\n",
        "  \n",
        "  '''\n",
        "\n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Applies Softmax function to the input and returns the result\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "       'activations' : numpy array of shape (batch, number_of_classes, 1, 1) or (Batch, number of classes)\n",
        "          activations on which Softmax funciton will be applied\n",
        "        \n",
        "        'train' : bool. Default = False\n",
        "          whether training of the layer is being carried out or not \n",
        "    '''\n",
        "\n",
        "    if train:\n",
        "      self.input_shape = activations.shape\n",
        "\n",
        "    \n",
        "    #check for correct shape of activations\n",
        "    if len(activations.shape) == 4:\n",
        "      \n",
        "      if activations.shape[-2:] != (1,1):\n",
        "        sys.exit(\"When using Global Average Poooling Technique (i.e the len of shape of activations is 4),\"\\\n",
        "         \"it can only be of form (batch, number of classes, 1,1)\")\n",
        "      else:  \n",
        "        activations = activations.reshape(activations.shape[0], activations.shape[1]) #reshape activations\n",
        "    \n",
        "    elif len(activations.shape) == 2:\n",
        "      pass\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"The number of dimensions of activations are not correct. It can either be two or four\")\n",
        "\n",
        "\n",
        "    #unnormalized probabilities\n",
        "    unnorm_prob = np.exp(activations)  #in order to avoid NaN\n",
        "\n",
        "    #normalized probabilities\n",
        "    output = unnorm_prob / (np.sum(unnorm_prob, axis=1).reshape(-1,1))\n",
        "\n",
        "    self.activations = output\n",
        "   \n",
        "    #calculate local gradient\n",
        "    if train:\n",
        "      self.output_shape = output.shape\n",
        "      \n",
        "      # derivative of this layer results in a jacobian of size (nunber of classes, number of classes) for each example.\n",
        "      # however, since we are dealing with one hot encoded values, the important values in jacobian are at the diagonals\n",
        "      # which are calcualted as follows:\n",
        "      self.dS = np.multiply(output, (1-output))\n",
        "\n",
        "    return output\n",
        "\n",
        "  def backward (self, dL):\n",
        "    '''\n",
        "      Calculates and returns gradient with respect to inputs to this layer\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        'dL' : numpy array of shape (same as output of this layer) \n",
        "          global gradient (flowing from the next layer)\n",
        "  \n",
        "    '''\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the Softmax layer\") \n",
        "    \n",
        "    #dX\n",
        "    return (dL*self.dS).reshape(self.input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9YgsjMlnw9F"
      },
      "source": [
        "# Pooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V75yCu11owbH"
      },
      "source": [
        "class Pool:\n",
        "  '''\n",
        "    Returns an object of \"Pool\" class that can be used as Pooling Layer in CNNs.\n",
        "\n",
        "    Paramters:\n",
        "\n",
        "      'pooling_type' : str = 'max', 'average' or 'global' \n",
        "        It defines which type of pooling to be applied on the activation maps. It can take one of the following values:\n",
        "\n",
        "          'max': outputs maximum value of region of activation map under the window\n",
        "          'average' or 'global': outputs mean value of region of activation map under the window\n",
        "\n",
        "      'filter_size' : non-zero, positive, int (optional when using 'pooling_type' = 'global')\n",
        "        size of the square window that needs to operate over each activation map\n",
        "      \n",
        "      'stride' : non-zero, positive, int. Default=2 (optional)\n",
        "        size of step to take in horizontal and vertical direction\n",
        "\n",
        "      'zero_padding' : positive, int. Default=0 (i.e. no zero padding) (optional)\n",
        "        number of rows and columns of zeros that needs to be added around each activation map.\n",
        "          For example, if it is specified to be as 2 and activations has a shape of (batch, channels, rows, cols), then \n",
        "          after zero padding, the new shape of activations will be (batch, channels, rows + 4, cols + 4) with zeros above and below, right and left of the axis -1 and -2.\n",
        "\n",
        "  Notes:\n",
        "\n",
        "    -  Combination of stride, zero padding, last two axis of both filter and activation maps must be \n",
        "    such that it results in an whole number for the following equation:\n",
        "\n",
        "              For each axis: \n",
        "                      O = ( ( R - F + 2P ) / S ) + 1 \n",
        "              where\n",
        "                      O = size of output axis\n",
        "                      R = size of activation map axis\n",
        "                      F = size of filter\n",
        "                      P = amount of zero padding\n",
        "                      S = stride\n",
        "\n",
        "    -  When using 'global' as 'pooling type', following parameters will be set as:\n",
        "              \n",
        "              'filter_size' = size of last two axis of activation map (rows, cols)\n",
        "              'stride' = 1\n",
        "              'zero_padding' = 0\n",
        "      \n",
        "       Thus, these parameters are not required. In case, if they are provided then they will be overwritten.\n",
        "  \n",
        "  '''\n",
        "  def __init__(self, pooling_type, filter_size=None, stride=1, zero_padding=0 ):\n",
        "\n",
        "    self.pooling_type = pooling_type\n",
        "\n",
        "    #assign function for corresponding pooling type\n",
        "    if pooling_type == 'max':\n",
        "      self.poolFnt=np.max\n",
        "    \n",
        "    elif pooling_type == 'average':\n",
        "      self.poolFnt=np.mean\n",
        "   \n",
        "    elif pooling_type == 'global':\n",
        "      \n",
        "      self.poolFnt = np.mean\n",
        "      self.stride = 1\n",
        "      self.zero_padding = 0\n",
        "\n",
        "    else:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'pooling_type'.It can only be 'max', 'average' or 'global' (with single quotes).\")\n",
        "\n",
        "\n",
        "    #Check for errors in input values\n",
        "\n",
        "    if pooling_type != 'global' and filter_size == None:\n",
        "      sys.exit(\"When not using 'global' as pooling type, 'filter_size' must be provided\")\n",
        "  \n",
        "    if pooling_type != 'global':\n",
        "\n",
        "      if filter_size <= 0 or filter_size % 1 != 0: \n",
        "        sys.exit(\"Invalid Value provided for parameter 'filter_size'. It must be non-zero, positive integer.\")\n",
        "      else:\n",
        "        self.filter_size=filter_size\n",
        "      \n",
        "      if stride <= 0 or stride % 1 !=0:\n",
        "        sys.exit(\"Invalid Value provided for parameter 'stride'.It must be non-zero, positive integer.\")\n",
        "      else:\n",
        "        self.stride = stride\n",
        "      \n",
        "      if zero_padding < 0 or zero_padding  % 1 !=0:\n",
        "        sys.exit(\"Invalid Value provided for parameter 'zero_padding'.It must be positive integer.\")\n",
        "      else:\n",
        "        self.zero_padding=zero_padding\n",
        "\n",
        "    \n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Performs Pooling of the activation maps and returns the result (shape = (b, d, r, c)):\n",
        "\n",
        "          b = batch (same as 'activations')\n",
        "          d = channels (same as 'activations')\n",
        "          r, c = Rows and Columns (calculated using the formula described in the constructor of the class) \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "      'activations' : numpy array of shape (batch, channels, rows, columns)\n",
        "        Activation map upon which pooling will be performed\n",
        "\n",
        "      'train' : bool. Default = False (optional)\n",
        "        whether training of the layer is being carried out or not \n",
        "\n",
        "    '''\n",
        "    #check whether valid value for activations is provided\n",
        "\n",
        "    if len(activations.shape) != 4:\n",
        "      sys.exit(\"The shape of the activations is incorrect. It must be (batch, channels, rows, cols). \")\n",
        "\n",
        "    if activations.shape[-1] != activations.shape[-2]:\n",
        "        sys.exit(\"The rows and columns (i.e axis =-1 and -2) of Activations must be same for pooling. \")\n",
        "    \n",
        "    #Adjust filter size for global average pooling \n",
        "    if self.pooling_type == 'global':\n",
        "      self.filter_size = activations.shape[-1]\n",
        "    \n",
        "    #Apply Zero padding\n",
        "    pw=[[0,0]]*(np.size(activations.shape)-2) + [[self.zero_padding, self.zero_padding]]*2 #list of pad widths for each axis\n",
        "    activations = np.pad(activations, pw, 'constant', constant_values=0)\n",
        "\n",
        "    # Calculate shape of output\n",
        "    output_row_col = ( ( np.array(activations.shape[-2:] ) - self.filter_size ) / self.stride) +1\n",
        "\n",
        "    #check whether filter and activations convolve properly\n",
        "    if all(output_row_col%1 !=0) :\n",
        "      print('Properties at this layer:')\n",
        "      print('\\t Layer = Pooling with ', self.pooling_type )\n",
        "      print('\\t Size of Activations (with zero padding) = ', activations.shape )\n",
        "      print('\\t\\t\\t ( batch, channels, rows, columns )')\n",
        "      print('\\t Size of window = ', (self.filter_size, self.filter_size) )\n",
        "      print('\\t Padding = ',  self.zero_padding )\n",
        "      print('\\t Stride = ' , self.stride )\n",
        "      \n",
        "      sys.exit('Undefined Values at Boundary of Activation Map: '\\\n",
        "               'Combination of stride, zero padding, last two axis (axis=-1,-2) of both window and activation maps is not correct.'\\\n",
        "               'Properties at this layer are printed above. For more, see the documentation of \"Pool\" class')\n",
        "      \n",
        "    \n",
        "    #array of zeros for output of pooling operation\n",
        "    output=np.zeros((activations.shape[0:2] + tuple(output_row_col.astype(np.int))))\n",
        "    \n",
        "    if train:\n",
        "      self.inputs_shape = activations.shape\n",
        "      self.output_shape = output.shape\n",
        "    \n",
        "      #for storing indices for local gradient\n",
        "      self.indices=np.empty((output.shape[-2:]), object)\n",
        "\n",
        "\n",
        "    for rows in range(output.shape[-2]):\n",
        "\n",
        "      for cols in range(output.shape[-1]):\n",
        "        \n",
        "        #adusting values with stride\n",
        "        r=rows*self.stride\n",
        "        c=cols*self.stride\n",
        "        \n",
        "        #pooling \n",
        "        result=self.poolFnt(activations[:,:, r:r + self.filter_size , c:c + self.filter_size], axis=(-2,-1))\n",
        "\n",
        "        if train:\n",
        "\n",
        "          # find indices for local gradient when 'pooling_type' is 'max'\n",
        "          if self.poolFnt.__name__ == 'amax':\n",
        "\n",
        "            #indices where highest value occurs \n",
        "            value_indices = np.where(np.equal(result[:,:,np.newaxis, np.newaxis], activations[:,:, r:r + self.filter_size, c:c + self.filter_size] ))\n",
        "            \n",
        "            #remove extra indices if multiple highest values exist\n",
        "            temp = np.array([value_indices[0], value_indices[1], value_indices[2], value_indices[3]]).T\n",
        "            _, uniq_indices = np.unique(np.array([value_indices[0],value_indices[1]]).T, return_index=True, axis=0) \n",
        "            \n",
        "            #store the indices\n",
        "            self.indices[rows,cols]= tuple([np.array(i) for i in temp[uniq_indices].T ])\n",
        "\n",
        "\n",
        "        output[:,:, rows, cols] = result\n",
        "    \n",
        "\n",
        "    return output\n",
        "\n",
        "  def backward(self, dL):\n",
        "    '''\n",
        "      Calculates and returns gradients with respect to input of this layer\n",
        "          \n",
        "      Parameters:\n",
        "\n",
        "      'dL' : numpy array of shape (same as output of this layer)\n",
        "        Global gradient flowing from the next layer\n",
        "\n",
        "    '''\n",
        "\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the Pooling layer\")   \n",
        "\n",
        "    dX=np.zeros(self.inputs_shape)\n",
        "    \n",
        "    #calculate Gradient \n",
        "    for rows in range(dL.shape[-2]):\n",
        "\n",
        "      for cols in range(dL.shape[-1]):\n",
        "        \n",
        "        #adusting values with stride\n",
        "        r=rows*self.stride\n",
        "        c=cols*self.stride\n",
        "\n",
        "        #dX\n",
        "        if self.poolFnt.__name__ == 'amax':\n",
        "          dX[:,:, r:r + self.filter_size , c:c + self.filter_size][self.indices[rows,cols]] += dL[:,:,rows, cols].flatten()\n",
        "        \n",
        "        else:\n",
        "          dX[:,:, r:r + self.filter_size , c:c + self.filter_size] += (dL[:,:,rows,np.newaxis, cols, np.newaxis]/(self.filter_size*self.filter_size))\n",
        "\n",
        "    #remove zero padding\n",
        "    return dX[:,:, self.zero_padding:dX.shape[-2]-self.zero_padding, self.zero_padding:dX.shape[-1]-self.zero_padding]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aGfdexdtt_R"
      },
      "source": [
        "# Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dHaDS6Et0_J"
      },
      "source": [
        "class FC:\n",
        "  '''\n",
        "    Returns an object of \"FC\" class that can be used as fully connected layer in CNNs\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'neurons' : non-zero, positive, int\n",
        "        Number of Neurons in the Fully Connected Layer\n",
        "  '''\n",
        "  def __init__(self, neurons):\n",
        "    \n",
        "    #check whether valid value is provided for 'neurons'\n",
        "    if neurons <= 0 or neurons % 1 != 0: \n",
        "        sys.exit(\"Invalid Value provided for parameter 'neurons'. It must be non-zero, positive integer.\")\n",
        "    else:\n",
        "        self.neurons = neurons\n",
        "\n",
        "    #variables asscoiated with this layer  \n",
        "    \n",
        "    self.weights=np.array([])\n",
        "    self.dW=np.array([])\n",
        "\n",
        "    self.bias=np.array([])\n",
        "    self.dB=np.array([])\n",
        "  \n",
        "  def forward(self, activations, train=False):\n",
        "    '''\n",
        "      Performs the following operation and returns the result of shape = (Batch, neurons in this layer)\n",
        "\n",
        "          result = activations*weight + bias\n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'activations' : numpy array of shape (batch, channels, rows, columns) or (Batch, neurons in previous layer)\n",
        "          activations which will be connected to fully connected layer\n",
        "        \n",
        "        'train' : bool. Default = False (optional)\n",
        "          whether training of the layer is being carried out or not \n",
        "      \n",
        "      Notes:\n",
        "\n",
        "        -  If 'activations' is of shape (batch, channels, rows columns), then it will be reshaped into (Batch, Channels*Rows*Cols)\n",
        "   \n",
        "   '''\n",
        "    if train:\n",
        "      self.inputs_shape = activations.shape\n",
        "\n",
        "    #Check whether valid values are provided for parameters\n",
        "\n",
        "    if len(activations.shape) == 4:\n",
        "      activations = activations.reshape(activations.shape[0], np.prod(activations.shape[1:]))\n",
        "  \n",
        "    elif len(activations.shape) == 2:\n",
        "      pass\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"The number of dimensions of activations are not correct. It can either be two or four\")\n",
        "\n",
        "    \n",
        "    if self.weights.shape[1] != self.neurons or self.bias.shape[0] != self.neurons:\n",
        "      sys.exit(\"The number of neurons in weights or bias do not match with number of neurons specified.\")\n",
        "       \n",
        "    if activations.shape[1] != self.weights.shape[0]:\n",
        "      sys.exit(\"There is a mismatch in number of neurons in previous layer between activations and weights. The second axis of activations do not match with the first axis of weights.\")\n",
        "    \n",
        "    if self.bias.shape[1] != 1:\n",
        "        sys.exit(\"Invalid Shape of parameter 'bias'. It must be of shape (number of neurons,1)\")\n",
        "    \n",
        "    self.bias = self.bias\n",
        "    \n",
        "    #Apply the Linear function\n",
        "    output = np.matmul(activations, self.weights) + self.bias.reshape(1,-1)\n",
        "    \n",
        "    #For gradients\n",
        "    if train:\n",
        "      self.inputs = activations\n",
        "      self.output_shape = output.shape\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "  def backward(self, dL):\n",
        "    '''\n",
        "      Calculates gradients with respect to weights and bias of this layer. \n",
        "      It also calculates and returns gradeints w.r.t inputs to this layer.\n",
        "          \n",
        "      Parameters:\n",
        "\n",
        "      'dL' : numpy array of shape (same as output of this layer)\n",
        "        Global gradient flowing from the next layer\n",
        "\n",
        "    '''\n",
        "    if dL.shape != self.output_shape:\n",
        "      sys.exit(\"The shape of global gradient must be same as output of the Fully Connected layer\")\n",
        "\n",
        "    #dW\n",
        "    self.dW = np.dot(self.inputs.T, dL)\n",
        "\n",
        "    #dB\n",
        "    self.dB = np.sum(dL, axis=0).reshape(-1,1)\n",
        "\n",
        "    #dX\n",
        "    return np.dot(dL, self.weights.T).reshape(self.inputs_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0dxfEEMZCK7"
      },
      "source": [
        "# Cross Entropy Loss layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohXUYDNjYwwD"
      },
      "source": [
        "class CELoss:\n",
        "  '''\n",
        "    Returns an object of \"CELoss\" class that can be used as cross entropy loss for Multiclass Classification in CNNs\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'number_of_classes' : non-zero, positive, int\n",
        "        Number of classes present in the dataset\n",
        "    \n",
        "      Notes:\n",
        "\n",
        "        - 'actual_labels' even though not one hot encoded, are used in calculations in such a way that they work like one hot encoded values.\n",
        "\n",
        "  '''\n",
        "  def __init__(self, number_of_classes):\n",
        "\n",
        "    #check whther valid value is provided for 'number_of_classes'\n",
        "    if number_of_classes <= 0 or number_of_classes % 1 != 0: \n",
        "      sys.exit(\"Invalid Value provided for parameter 'number_of_classes'. It must be non-zero, positive integer.\")\n",
        "    else:\n",
        "      self.number_of_classes = number_of_classes\n",
        "    \n",
        "\n",
        "  def forward (self, activations, labels, train=False):\n",
        "    '''\n",
        "    Calculates and returns total Cross Entropy loss (not divided by total number of training examples).\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'activations' : numpy array of shape (batch, number of classes)\n",
        "        activations which will used for calculating cross entropy loss\n",
        "\n",
        "      'labels' : numpy array of shape (batch, 1)\n",
        "        label of each training example. They must be positive integers and must range between 0 and number_of_classes - 1.\n",
        "\n",
        "       'train' : bool. Default = False (optional)\n",
        "          whether training of the layer is being carried out or not \n",
        "    \n",
        "    Notes:\n",
        "\n",
        "      - Natural Log is used for the calculation of loss function   \n",
        "\n",
        "    '''\n",
        "\n",
        "    #Check whether inputs' shape and values are correct\n",
        "  \n",
        "    if activations.shape[1] != self.number_of_classes:\n",
        "      sys.exit(\"The number of classes specified do not match with the number of neurons in the last layer. These two must be same\")\n",
        "\n",
        "    if activations.shape[0] != labels.shape[0]:\n",
        "      sys.exit(\"There is a mismatch in number of examples in activations and in labels provided.\")\n",
        "    \n",
        "    if labels.shape[1] != 1 or len(labels.shape) != 2:\n",
        "      sys.exit(\"The shape of 'labels' is not correct. It can only be (batch,1)\")\n",
        "    \n",
        "    unique_labels = np.unique(labels)\n",
        "\n",
        "    if any(unique_labels < 0) or any(unique_labels % 1 != 0): \n",
        "      sys.exit(\"Invalid Value provided for parameter 'labels'. It can only be positive integer.\")\n",
        "    \n",
        "    if len(unique_labels) > self.number_of_classes: \n",
        "      sys.exit(\"There are more classes in 'labels' than specified.\")\n",
        "    \n",
        "    if not set(unique_labels).issubset( range(0, self.number_of_classes) ): \n",
        "      sys.exit(\"The integers in 'labels' do no fall in range between 0 and number of classes - 1.\")\n",
        "\n",
        "    #Annotating labels with number of training example\n",
        "    label_with_img_no = tuple( [range(activations.shape[0]), labels.reshape(-1)] )\n",
        "\n",
        "    #calculate local gradient\n",
        "    if train:\n",
        "      self.dC = np.zeros(activations.shape, dtype=np.float)\n",
        "      self.dC [label_with_img_no] = -1/(activations[label_with_img_no])\n",
        "\n",
        "    #calculate loss\n",
        "    loss = - np.log( activations[label_with_img_no])\n",
        "\n",
        "    return np.sum( loss )\n",
        "\n",
        "\n",
        "  def backward(self, dL):\n",
        "    '''\n",
        "      Calculates and returns gradients with respect to inputs of this layer. \n",
        "      \n",
        "      Parameters:\n",
        "\n",
        "      'dL' : int/float\n",
        "        Global gradient flowing from the next layer\n",
        "\n",
        "    '''\n",
        "    #dX\n",
        "    return dL*self.dC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-E-FLloLdji"
      },
      "source": [
        "# Evaluation Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YH9YIxALi7K"
      },
      "source": [
        "## Classification Accuary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qYoXmqOMkp6"
      },
      "source": [
        "def ClassAccu(activations, actual_labels):\n",
        "  '''\n",
        "     Returns number of correctly classified examples in the batch\n",
        "\n",
        "     Parameters:\n",
        "\n",
        "       'activations' : numpy array of shape (batch, number of classes)\n",
        "         activations of output layer (layer before loss function).  \n",
        "      \n",
        "       'actual_labels' : numpy array of shape (batch,1)\n",
        "         actual labels of each example  \n",
        "      \n",
        "      Notes:\n",
        "\n",
        "        - 'actual_labels', even though not one hot encoded, are used in calculations in such a way that they work like one hot encoded values.\n",
        "\n",
        "  '''\n",
        "    \n",
        "  #indexes of highest values\n",
        "  pred_labels=np.where(np.max(activations, axis=1, keepdims=True) == activations )\n",
        "  \n",
        "  #remove those rows in case when more than one class have equal highest score\n",
        "  temp=np.array([pred_labels[0],pred_labels[1]]).T\n",
        "  _,indices=np.unique(pred_labels[0], return_index=True) \n",
        "\n",
        "  #calculate and return percentage of correctly classified examples\n",
        "  return np.sum(temp[indices][:,1] == actual_labels.reshape(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9QkF0dhMmMw"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWzBQztrMpZd"
      },
      "source": [
        "def ConfMatrix(activations, actual_labels):\n",
        "  '''\n",
        "     Returns Confusion Matrix (numpy array) of shape (number of classes, number of classes)\n",
        "         Rows represent predicted labels and Columns represent actual labels.\n",
        "\n",
        "     Parameters:\n",
        "\n",
        "       'activations' : numpy array of shape (batch, number of classes)\n",
        "         activations of output layer (layer before loss function).  \n",
        "      \n",
        "       'actual_labels' : numpy array of shape (batch,1)\n",
        "         actual labels of each example  \n",
        "    \n",
        "    Notes:\n",
        "\n",
        "    - 'actual_labels', even though not one hot encoded, are used in calculations in such a way that they work like one hot encoded values.\n",
        "  '''\n",
        "    \n",
        "  #indexes of highest values\n",
        "  pred_labels = np.where(np.max(activations, axis=1, keepdims=True) == activations )\n",
        "\n",
        "  #remove those rows in case when more than one label have equal highest score\n",
        "  temp = np.array([pred_labels[0],pred_labels[1]]).T\n",
        "  _,indices = np.unique(pred_labels[0], return_index=True) \n",
        "\n",
        "  #concentate indices of predicted and actual labels\n",
        "  temp = np.concatenate((temp[indices][:,1].reshape(-1,1), actual_labels), axis=1)\n",
        "\n",
        "  #confusion matrix\n",
        "  cm = np.zeros((activations.shape[1], activations.shape[1]))\n",
        "  for x,y in temp:\n",
        "    cm[x, y] = cm[x, y] +1\n",
        "\n",
        "  return cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYqBXweoJuDB"
      },
      "source": [
        "# Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGwpY1s4JyQ2"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABV-4CjylJcy"
      },
      "source": [
        "class GD:\n",
        "  '''\n",
        "    Returns an object of \"GD\" class that can be used as optimizer in CNNs.\n",
        "    It uses Vanilla Gradient Descent algorithm to update the parameters.\n",
        "    Further, it may be noted that it uses L2 regularization\n",
        "\n",
        "  '''\n",
        "  def update(self, layer, batch_size, lmbda, lr):\n",
        "    '''\n",
        "      Updates parameters of the layer\n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'layer' : object of class 'Conv' or 'FC'\n",
        "          layer whose weights will be updated\n",
        "        \n",
        "        'batch_size' : non-zero positive int \n",
        "          size of batch.\n",
        "\n",
        "        'lmbda' : int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        'lr' : int or float\n",
        "          value of learning rate\n",
        "\n",
        "    '''\n",
        "    if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC': \n",
        "\n",
        "      #adjust for regularization and update paramters\n",
        "      layer.weights += - lr * ((layer.dW + (lmbda*layer.weights))/batch_size)\n",
        "      layer.bias += -lr *(layer.dB/batch_size)\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"Invalid Layer for parameters updation\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEMnVZculKvb"
      },
      "source": [
        "## Gradient Descent with Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc5LuvZllLre"
      },
      "source": [
        "class GDM:\n",
        "  '''\n",
        "    Returns an object of \"GDM\" class that can be used as optimizer in CNNs.\n",
        "    It uses Gradient Descent with Momentum algorithm to update the parameters.\n",
        "    Further, it may be noted that it uses L2 regularization\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'rho' : int or float\n",
        "        value of \"friction\"\n",
        "  '''\n",
        "  def __init__(self, rho):\n",
        "    self.rho = rho\n",
        "\n",
        "\n",
        "  def update(self, layer, batch_size, lmbda, lr):\n",
        "    '''\n",
        "      Updates parameters of the layer \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'layer' : object of class 'Conv' or 'FC'\n",
        "          layer whose weights will be updated\n",
        "        \n",
        "        'batch_size' : non-zero postive int \n",
        "          size of batch.\n",
        "\n",
        "        'lmbda' : int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        'lr' : int or float\n",
        "          value of learning rate\n",
        "\n",
        "    '''\n",
        "    if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC': \n",
        "      \n",
        "      #adjust for regularization\n",
        "      total_dW = (layer.dW + (lmbda*layer.weights))/batch_size\n",
        "      total_dB = layer.dB/batch_size\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dW_vel'):\n",
        "        layer.dW_vel = 0 \n",
        "      \n",
        "      print('dW_vel inside', dW_vel)\n",
        "      layer.dW_vel = (self.rho*layer.dW_vel) + total_dW\n",
        "      layer.weights += - lr * layer.dW_vel\n",
        "\n",
        "      #adjust for first iteration and update bias\n",
        "      if not hasattr(layer, 'dB_vel'):\n",
        "        layer.dB_vel = 0\n",
        "\n",
        "      layer.dB_vel = (self.rho*layer.dB_vel) + total_dB \n",
        "      layer.bias += - lr * layer.dB_vel\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"Invalid Layer for parameters updation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxwRge3jlMrL"
      },
      "source": [
        "## Nesterov Momentum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9TofrnUlN0B"
      },
      "source": [
        "class NM:\n",
        "  '''\n",
        "    Returns an object of \"NM\" class that can be used as optimizer in CNNs.\n",
        "    It uses Nestrov Momentum algorithm to update the parameters.\n",
        "    Further, it may be noted that it uses L2 regularization\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'rho' : int or float\n",
        "        value of \"friction\"\n",
        "  '''\n",
        "  def __init__(self, rho):\n",
        "    self.rho = rho\n",
        "\n",
        "\n",
        "  def update(self, layer, batch_size, lmbda, lr):\n",
        "    '''\n",
        "      Updates parameters of the layer \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'layer' : object of class 'Conv' or 'FC'\n",
        "          layer whose weights will be updated\n",
        "        \n",
        "        'batch_size' : non zero positive int \n",
        "          size of batch.\n",
        "\n",
        "        'lmbda' : int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        'lr' : int or float\n",
        "          value of learning rate\n",
        "\n",
        "    '''\n",
        "    if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC': \n",
        "      \n",
        "      #adjust for regularization\n",
        "      total_dW = (layer.dW + (lmbda*layer.weights))/batch_size\n",
        "      total_dB = layer.dB/batch_size\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dW_vel'):\n",
        "        layer.dW_vel = 0 \n",
        "      \n",
        "      old_dW_vel = layer.dW_vel\n",
        "      layer.dW_vel = (self.rho*layer.dW_vel) - (lr * total_dW)\n",
        "      layer.weights += - (self.rho*old_dW_vel) + ((1+self.rho) * layer.dW_vel)\n",
        "\n",
        "      #adjust for first iteration and update bias\n",
        "      if not hasattr(layer, 'dW_vel'):\n",
        "        layer.dB_vel = 0 \n",
        "       \n",
        "      old_dB_vel = layer.dB_vel\n",
        "      layer.dB_vel = (self.rho*layer.dB_vel) - (lr * total_dB)\n",
        "      layer.bias += - (self.rho*old_dB_vel) + ((1+self.rho) * layer.dB_vel)\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"Invalid Layer for parameters updation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7LGrCn1lSQ6"
      },
      "source": [
        "## AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLXEsptSlTTD"
      },
      "source": [
        "class AG:\n",
        "  '''\n",
        "    Returns an object of \"AG\" class that can be used as optimizer in CNNs.\n",
        "    It uses AdaGrad algorithm to update the parameters.\n",
        "    Further, it may be noted that it uses L2 regularization\n",
        "\n",
        "  '''\n",
        "\n",
        "  def update(self, layer, batch_size, lmbda, lr):\n",
        "    '''\n",
        "      Updates parameters of the layer \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'layer' : object of class 'Conv' or 'FC'\n",
        "          layer whose weights will be updated\n",
        "        \n",
        "        'batch_size' : non zero positive int \n",
        "          size of batch.\n",
        "\n",
        "        'lmbda' : int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        'lr' : int or float\n",
        "          value of learning rate\n",
        "\n",
        "    '''\n",
        "    if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC': \n",
        "      \n",
        "      #adjust for regularization\n",
        "      total_dW = (layer.dW + (lmbda*layer.weights))/batch_size\n",
        "      total_dB = layer.dB/batch_size\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dW_squared'):\n",
        "        layer.dW_squared = 0 \n",
        "      \n",
        "      layer.dW_squared += total_dW * total_dW\n",
        "      layer.weights += - (lr*total_dW)/(np.sqrt(layer.dW_squared) + 0.00000001 )\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dB_squared'):\n",
        "        layer.dB_squared = 0 \n",
        "      \n",
        "      layer.dB_squared += total_dB * total_dB\n",
        "      layer.bias += - (lr*total_dB)/(np.sqrt(layer.dB_squared) + 0.00000001 )\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"Invalid Layer for parameters updation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soGwab7ZlUBl"
      },
      "source": [
        "## RMSProp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEaz8B0zlXK_"
      },
      "source": [
        "class RP:\n",
        "  '''\n",
        "    Returns an object of \"RP\" class that can be used as optimizer in CNNs.\n",
        "    It uses RMSProp algorithm to update the parameters.\n",
        "    Further, it may be noted that it uses L2 regularization\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'decay_rate' : int or float\n",
        "        value of rate of decay of learning rate\n",
        "  '''\n",
        "  def __init__(self, decay_rate):\n",
        "    self.decay_rate = decay_rate\n",
        "\n",
        "\n",
        "  def update(self, layer, batch_size, lmbda, lr):\n",
        "    '''\n",
        "      Updates parameters of the layer \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'layer' : object of class 'Conv' or 'FC'\n",
        "          layer whose weights will be updated\n",
        "        \n",
        "        'batch_size' : non-zero positive int \n",
        "          size of batch.\n",
        "\n",
        "        'lmbda' : int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        'lr' : int or float\n",
        "          value of learning rate\n",
        "\n",
        "    '''\n",
        "    if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC': \n",
        "      \n",
        "      #adjust for regularization\n",
        "      total_dW = (layer.dW + (lmbda*layer.weights))/batch_size\n",
        "      total_dB = layer.dB/batch_size\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dW_squared'):\n",
        "        layer.dW_squared = 0 \n",
        "      \n",
        "      layer.dW_squared = (self.decay_rate * layer.dW_squared) + (( 1 - self.decay_rate ) * (total_dW * total_dW))\n",
        "      layer.weights += - ( lr*total_dW )/( np.sqrt(layer.dW_squared) + 0.00000001 )\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dB_squared'):\n",
        "        layer.dB_squared = 0 \n",
        "      \n",
        "      layer.dB_squared = (self.decay_rate * layer.dB_squared) + (( 1 - self.decay_rate ) * (total_dB * total_dB))\n",
        "      layer.bias += - (lr*total_dB)/(np.sqrt(layer.dB_squared) + 0.00000001 )\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"Invalid Layer for parameters updation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ponrpRBqlYub"
      },
      "source": [
        "## Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UErhgnZUlZnX"
      },
      "source": [
        "class AD:\n",
        "  '''\n",
        "    Returns an object of \"AD\" class that can be used as optimizer in CNNs.\n",
        "    It uses Adam algorithm to update the parameters.\n",
        "    Further, it may be noted that it uses L2 regularization\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'beta1' : int or float\n",
        "\n",
        "      'beta2' : int or float\n",
        "\n",
        "  '''\n",
        "  def __init__(self, beta1, beta2):\n",
        "    self.beta1 = beta1\n",
        "    self.beta2 = beta2\n",
        "\n",
        "\n",
        "  def update(self, layer, batch_size, lmbda, lr, iter):\n",
        "    '''\n",
        "      Updates parameters of the layer \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'layer' : object of class 'Conv' or 'FC'\n",
        "          layer whose weights will be updated\n",
        "        \n",
        "        'batch_size' : non zero postive int \n",
        "          size of batch.\n",
        "\n",
        "        'lmbda' : int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        'lr' : int or float\n",
        "          value of learning rate\n",
        "        \n",
        "        'iter' : non zero positive int\n",
        "          number of iteration\n",
        "\n",
        "    '''\n",
        "    if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC': \n",
        "      \n",
        "      #adjust for regularization\n",
        "      total_dW = (layer.dW + (lmbda*layer.weights))/batch_size\n",
        "      total_dB = layer.dB/batch_size\n",
        "\n",
        "      #adjust for first iteration and update weights\n",
        "      if not hasattr(layer, 'dW_first_moment'):\n",
        "        layer.dW_first_moment = 0 \n",
        "      if not hasattr(layer, 'dW_second_moment'):\n",
        "        layer.dW_second_moment = 0\n",
        "\n",
        "      layer.dW_first_moment = (self.beta1 * layer.dW_first_moment) + ( (1-self.beta1) *total_dW)   \n",
        "      layer.dW_second_moment = (self.beta2 * layer.dW_second_moment) + (( 1 - self.beta2 ) * (total_dW * total_dW))\n",
        "      \n",
        "      first_unbias = layer.dW_first_moment / (1 - self.beta1 ** iter)\n",
        "      second_unbias = layer.dW_second_moment / (1 - self.beta2 ** iter)\n",
        "      \n",
        "      layer.weights += - ( lr*first_unbias )/( np.sqrt(second_unbias) + 0.00000001 )\n",
        "\n",
        "      #adjust for first iteration and update bias\n",
        "      if not hasattr(layer, 'dB_first_moment'):\n",
        "        layer.dB_first_moment = 0 \n",
        "      if not hasattr(layer, 'dB_second_moment'):\n",
        "        layer.dB_second_moment = 0\n",
        "\n",
        "      layer.dB_first_moment = (self.beta1 * layer.dB_first_moment) + ( (1-self.beta1) * total_dB)   \n",
        "      layer.dB_second_moment = (self.beta2 * layer.dB_second_moment) + (( 1 - self.beta2 ) * (total_dB * total_dB))\n",
        "      \n",
        "      first_unbias = layer.dB_first_moment / (1 - self.beta1 ** iter)\n",
        "      second_unbias = layer.dB_second_moment / (1 - self.beta2 ** iter)\n",
        "      \n",
        "      layer.bias += - ( lr*first_unbias )/( np.sqrt(second_unbias) + 0.00000001 )\n",
        "\n",
        "    \n",
        "    else:\n",
        "      sys.exit(\"Invalid Layer for parameters updation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-pkhmTouZmq"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqTAq29munPr"
      },
      "source": [
        "class Network:\n",
        "\n",
        "  '''\n",
        "    Returns an object of 'Network' class that is used for building and training the CNN model. \n",
        "\n",
        "    Parameters:\n",
        "    \n",
        "      'layers' : list of class objects. \n",
        "        This list defines the architecture of the network.\n",
        "        It can be have objects of classes:\n",
        "          'Conv', 'ReLU', 'Tanh', 'LeakyReLU', 'Pool', 'FC', 'Softmax' or 'CELoss'.\n",
        "        \n",
        "\n",
        "      'weights_init' : int, float, 'Gauss', 'Xavier' or 'He'\n",
        "        This paramter determines how to initialize the weights in the network. \n",
        "        It can take one of the following values:\n",
        "            \n",
        "            int or float: all weights will be initialized with this value\n",
        "            'Gauss' : pick random numbers from simple Gaussian Distribution with specified mean and standard deviation\n",
        "            'Xavier' : same as 'Gauss' except mean = 0 and standard deviation = 1/sqrt(number of input neurons)\n",
        "            'He' : same as 'Gauss' except mean = 0 and standard deviation = 1/sqrt(number of input nerons/2)\n",
        "\n",
        "      'bias_init' : int, float or 'Gauss'\n",
        "        This parameter determines how to initialize the biases in the network.\n",
        "\n",
        "      'mean' : int / float (not optional when using 'Gauss')\n",
        "        Mean of the Gaussian distribution\n",
        "\n",
        "      'std' : non negative float (not optional when using 'Gauss')\n",
        "        Standard Deviation of the Gaussian distribution\n",
        "      \n",
        "      'optimizer' : object of a class\n",
        "        The methodology to use for updating weights. It can be an object of one of the following classes:\n",
        "          'GD', 'GDM', 'NM', 'AG', 'RP', or 'AD'\n",
        "\n",
        "      'eval_metric' : list of functions: ClassAccu or ConfMatrix (optional). \n",
        "        metrics on which the model will be evaluated. The list can contain upto two values. For more info, see notes.\n",
        "\n",
        "    Notes:\n",
        "      \n",
        "      - For a CNN with two convolution layers, two pooling layers and two fully connected layer with ReLU as activation function\n",
        "        and Cross entropy as Loss function, the parameter 'layers' with these classes' objects would look like as follows:\n",
        "          \n",
        "          [Conv, ReLU, Pool, Conv, ReLU, Pool, FC, ReLU, FC, Softmax, CELoss]\n",
        "        \n",
        "        The layer before loss function is output layer and it must have neurons equal to number of classes.\n",
        "        \n",
        "      - When using 'Gauss', weights and biases will use same mean and same standard deviation for initialization. \n",
        "        When using only for weights (or biases), they must be provided.\n",
        "\n",
        "      - 'Xavier' performs Xavier initialization and 'He' performs He initialization of weights. In either case, parameter 'mean'\n",
        "        and 'std' are not required. If provided, they will be overwritten.\n",
        "\n",
        "      - When using 'Xavier' or 'He', the number of input neurons for Convolution layer will be equal to filter_size*filter_size*channels\n",
        "        and for Fully Connected layer, it will be equal to number of neurons in the previous layer.\n",
        "    \n",
        "      - If no value is passed to 'eval_metric', no evaluation method will be used. This parameter must be a list.\n",
        "        It can take any one of the forms: [ClassAccu],[ConfMatrix],[ClassAccu, ConfMatrix] or [ConfMatrix,ClassAccu] \n",
        "\n",
        "  '''\n",
        "  def __init__(self, layers, weights_init, bias_init,  optimizer, mean=None, std=None, eval_metric=None):\n",
        "    \n",
        "    #Check whether valid values are provided for parameter 'layers' \n",
        "\n",
        "    possible_layers = ['Conv', 'ReLU',  'Tanh', 'LeakyReLU', 'Pool', 'FC', 'Softmax', 'CELoss']\n",
        "\n",
        "    if type(layers) != list:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'layers'. It must be a list\")\n",
        "    else:\n",
        "      uni_layers = np.unique([type(layer).__name__ for layer in layers])\n",
        "    \n",
        "    if len(layers) == 0:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'layers'. It cannot be empty\")\n",
        "    elif not set(uni_layers).issubset(possible_layers):\n",
        "      sys.exit(\"Invalid Layer provided.\")\n",
        "    else:\n",
        "      self.layers = layers\n",
        "\n",
        "    \n",
        "    #Check whether weights/bias' initialization parameters are provided with valid values\n",
        "    if weights_init == 'Gauss' or bias_init == 'Gauss':\n",
        "\n",
        "      if mean == None:\n",
        "        sys.exit(\"Mean must be given when using 'Gauss' for initialization of weights/bias\")\n",
        "      else:\n",
        "        self.mean = mean\n",
        "      \n",
        "      if std == None:\n",
        "        sys.exit(\"Standard Deviation must be given when using 'Gauss' for initialization of weights/bias\")     \n",
        "      elif std < 0:\n",
        "          sys.exit(\"Standard Deviation can not be negative\")\n",
        "      else:\n",
        "          self.std = std\n",
        "\n",
        "\n",
        "    #Assign corresponding funcitons for weight/bias initialization\n",
        "    \n",
        "    #Flags for constant value parameter initialization\n",
        "    self.WeightFlag =False\n",
        "    self.BiasFlag = False\n",
        "    \n",
        "    if (type(weights_init) == int) or (type(weights_init) == float):\n",
        "      self.WeightInitFnt = self.FillConstValue\n",
        "      self.WeightFlag =True\n",
        "      self.WeightValue = weights_init\n",
        "    \n",
        "    elif (weights_init == 'Gauss') or (weights_init == 'Xavier') or (weights_init == 'He'):\n",
        "      self.WeightInitFnt = self.GaussDist\n",
        "      self.WeightValue = weights_init\n",
        "\n",
        "    else:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'weights_init'. It can either be int, float, 'Gauss', 'Xavier', or 'He'.\")\n",
        "\n",
        "    if (type(bias_init) ==  int) or (type(bias_init) == float):\n",
        "      self.BiasInitFnt = self.FillConstValue\n",
        "      self.BiasFlag =True\n",
        "      self.BiasValue = bias_init\n",
        "    \n",
        "    elif bias_init == 'Gauss':\n",
        "      self.BiasInitFnt = self.GaussDist\n",
        "      self.BiasValue =bias_init\n",
        "      \n",
        "    else:\n",
        "      sys.exit(\"Invalid Value provided for parameter 'bias_init'.It can either be int, float, or 'Gauss'.\") \n",
        "\n",
        "    #Check whether valid values for optimizer is provided\n",
        "\n",
        "    possible_optimizers = ['GD', 'GDM', 'NM', 'AG', 'RP', 'AD']\n",
        "\n",
        "    if type(optimizer).__name__ not in possible_optimizers:\n",
        "      sys.exit(\"Invalid value provided for parameter 'optimizer'\")\n",
        "    else: \n",
        "      self.optimizer = optimizer\n",
        "\n",
        "    #Check and assign evaluation metrics \n",
        "    if (eval_metric != None):\n",
        "        \n",
        "        if len(eval_metric) == 0:\n",
        "            self.eval_metric = None\n",
        "        elif len(eval_metric) > 2:\n",
        "            sys.exit(\"Too many values for 'eval_metric': The length of list cannot exceed 2.\")\n",
        "        else:\n",
        "            for metric in eval_metric:\n",
        "\n",
        "                if metric.__name__ != 'ClassAccu' and metric.__name__ != 'ConfMatrix':\n",
        "                    sys.exit(\"Invalid Evaluation Accuracy Metric provided: It can take only these functions: 'ClassAccu' and 'ConfMatrix' \")\n",
        "        \n",
        "        self.eval_metric = eval_metric\n",
        "\n",
        "    #flag for parameter initialization\n",
        "    self.flag = True\n",
        "\n",
        "\n",
        "  def FillConstValue(self, shape, fill_value):\n",
        "    '''\n",
        "      Returns array of specified shape, filled with specified value \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'shape' : tuple of ints\n",
        "          output shape of the array\n",
        "        \n",
        "        'fill_value' : int or float\n",
        "          value which will be filled in the array\n",
        "\n",
        "    ''' \n",
        "    return np.full(shape, fill_value = fill_value)\n",
        "\n",
        "\n",
        "\n",
        "  def GaussDist(self, shape, type_init):\n",
        "    '''\n",
        "      Returns array of specified shape, whose values obtained randomly from Gaussian Distribution \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'shape' : tuple of ints as either (number_of_filters, channels, filter_size, filter_size) or (neurons in previous layer, neurons in next layer)\n",
        "          output shape of array.\n",
        "       \n",
        "        'type_init' : 'Gauss', 'Xavier' or 'He'\n",
        "          This determines which method to use for initialization of parameters \n",
        "    \n",
        "    '''\n",
        "    #determine input neurons\n",
        "    if len(shape) == 4:\n",
        "      neuron_i = shape[-1]*shape[-2]*shape[-3]\n",
        "    \n",
        "    if len(shape) == 2:\n",
        "      neuron_i = shape[0] \n",
        "\n",
        "    if type_init == 'Gauss':\n",
        "      mean = self.mean\n",
        "      std = self.std\n",
        "\n",
        "    elif type_init == 'Xavier':\n",
        "      mean = 0\n",
        "      std = 1/np.sqrt(neuron_i)\n",
        "    \n",
        "    elif type_init == 'He':\n",
        "      mean =0\n",
        "      std = 1/np.sqrt(neuron_i/2)\n",
        "\n",
        "    else:\n",
        "      sys.exit(\"Unkown Type of parameters Initialization\")\n",
        "\n",
        "    return np.random.normal(mean, std, shape)\n",
        "     \n",
        "    \n",
        "\n",
        "  \n",
        "  def forward_propagate(self, X, Y, train):\n",
        "    '''\n",
        "      Performs forward propagation and returns Loss and accuracy\n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        'X' : numpy array of shape (batch, channels, rows, cols) \n",
        "          batch of input images upon which forward propagation will be carried out\n",
        "        \n",
        "        'Y' : numpy array of shape (batch,1)\n",
        "          label of each training example\n",
        "        \n",
        "        'train' : bool\n",
        "          determines whether function is being called for training or not \n",
        "\n",
        "    ''' \n",
        "    \n",
        "    activations = X\n",
        "\n",
        "    \n",
        "    for layer in self.layers:\n",
        "\n",
        "      if type(layer).__name__ == 'Conv' and self.flag:\n",
        "  \n",
        "        #intialize parameters\n",
        "        layer.weights = self.WeightInitFnt((layer.number_of_filters, activations.shape[1], layer.filter_size, layer.filter_size ), self.WeightValue)\n",
        "        layer.bias = self.BiasInitFnt((layer.number_of_filters,1), self.BiasValue)\n",
        "\n",
        "\n",
        "      if type(layer).__name__ == 'FC' and self.flag:\n",
        "\n",
        "        if len(activations.shape) == 4:\n",
        "          prev_layer_neurons = activations.shape[-1]*activations.shape[-2]*activations.shape[-3]\n",
        "        elif len(activations.shape) == 2:\n",
        "          prev_layer_neurons = activations.shape[1]\n",
        "        else:\n",
        "          sys.exit(\"Unknown activation shape for Fully Connected Layers\")\n",
        "\n",
        "        #initialize parameters      \n",
        "        layer.weights = self.WeightInitFnt((prev_layer_neurons , layer.neurons), self.WeightValue)\n",
        "        layer.bias = self.BiasInitFnt((layer.neurons,1), self.BiasValue)\n",
        "\n",
        "        \n",
        "      if type(layer).__name__ == 'CELoss':\n",
        "        loss = layer.forward(activations, Y, train)  \n",
        "        \n",
        "        return loss, accuracy \n",
        "\n",
        "      else:\n",
        "        activations = layer.forward(activations, train)\n",
        "\n",
        "\n",
        "      #Evaluate output on evaluation metrics \n",
        "      accuracy =[]  \n",
        "      if type(layer).__name__ == 'Softmax' and self.eval_metric != None:\n",
        "        \n",
        "        for metric in self.eval_metric:\n",
        "          accuracy.append(metric(activations, Y))\n",
        "\n",
        "    \n",
        "    #No initialization of parameters on further calls to this function\n",
        "    self.flag=False   \n",
        "    \n",
        "\n",
        "\n",
        "  def back_propagate(self):\n",
        "    '''\n",
        "      Performs back propagation\n",
        "\n",
        "    '''\n",
        "    #Gradient of output of last layer with itself\n",
        "    dL=1\n",
        "\n",
        "    for layer in reversed(self.layers):\n",
        "      dL=layer.backward(dL)\n",
        "\n",
        "\n",
        "\n",
        "  def update_parameters(self, batch_size, lmbda, lr, iter):\n",
        "    '''\n",
        "      Updates parameters of the layers\n",
        "\n",
        "      Parameters:\n",
        "        \n",
        "        batch_size: non zero postive int \n",
        "          size of batch. This determines the number of examples after which weights wiil be updated\n",
        "\n",
        "        lmbda: int or float\n",
        "          value of regulariztion parameter\n",
        "        \n",
        "        lr: int or float\n",
        "          value of learning rate\n",
        "\n",
        "        iter: nonzero positive int \n",
        "          number of iteration\n",
        "    '''\n",
        "    for layer in self.layers:\n",
        "      \n",
        "      if type(layer).__name__ == 'Conv' or type(layer).__name__ == 'FC':\n",
        "\n",
        "        if type(self.optimizer).__name__ == 'AD':\n",
        "          self.optimizer.update(layer, batch_size, lmbda, lr, iter)\n",
        "\n",
        "        else:\n",
        "          self.optimizer.update(layer, batch_size, lmbda, lr)\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  def gradient_check(self, X, Y):\n",
        "    '''\n",
        "      Performs checking of the analytically calculated gradients using numerical approach.\n",
        "      Also prints the dictionary which shows original parameters, original derivatives, calculated derivatives and percentage difference.\n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        X: numpy array of shape (batch, channels, rows, cols) \n",
        "          batch of input images.\n",
        "        \n",
        "        Y: numpy array of shape (batch,1)\n",
        "          labels of each training example\n",
        "\n",
        "    '''\n",
        "    #dictionary for storing parameters and derivatives (original, calculated, difference percentage) of layers\n",
        "    grad_network={}\n",
        "\n",
        "    for layer in self.layers:\n",
        "      \n",
        "      layer_name = type(layer).__name__\n",
        "      \n",
        "      if layer_name == 'Conv' or layer_name == 'FC':\n",
        "        \n",
        "        grad_network[layer_name] = {}\n",
        "\n",
        "        #store original parameters and derivatives\n",
        "        grad_network[layer_name]['weights_ori'] = layer.weights\n",
        "        grad_network[layer_name]['bias_ori'] = layer.bias\n",
        "        grad_network[layer_name]['deriv_weights_ori'] = layer.dW\n",
        "        grad_network[layer_name]['deriv_bias_ori'] = layer.dB\n",
        "        \n",
        "        #for storing deivative calculated numerically\n",
        "        deriv_weights_num = np.zeros(layer.weights.shape)\n",
        "        deriv_bias_num = np.zeros(layer.bias.shape)\n",
        "\n",
        "        #small value to be added to each parameter\n",
        "        e = 0.00001\n",
        "        \n",
        "        if layer_name == 'Conv':\n",
        "          \n",
        "          #For weights\n",
        "          for filter in range(layer.weights.shape[0]):\n",
        "            for channels in range(layer.weights.shape[1]):\n",
        "              for rows in range(layer.weights.shape[2]):\n",
        "                for cols in range(layer.weights.shape[3]):\n",
        "                  \n",
        "                  epsilon = np.zeros(layer.weights.shape)\n",
        "                  epsilon[filter, channels, rows, cols] = e\n",
        "                  cost = []\n",
        "\n",
        "                  #in first iteration add the epsilon value and calculate cost\n",
        "                  #in second iteartion subtract the epsilon value and calculate cost\n",
        "                  for k in range (0, 2, 1):\n",
        "\n",
        "\n",
        "                    if k==0:  \n",
        "                      layer.weights = grad_network[layer_name]['weights_ori'] + epsilon\n",
        "        \n",
        "                    else:\n",
        "                      layer.weights = grad_network[layer_name]['weights_ori'] - epsilon\n",
        "\n",
        "                    #forward propagation\n",
        "                    c, _ = self.forward_propagate(X, Y, train=False)\n",
        "\n",
        "                    #store cost\n",
        "                    cost.append(c/X.shape[0])\n",
        "\n",
        "                  #calculate and store numerically calculated derivative\n",
        "                  deriv_weights_num[filter, channels, rows, cols] = (cost[0]-cost[1])/(2*e)\n",
        "\n",
        "        if layer_name == 'FC':\n",
        "          \n",
        "          #For Weights\n",
        "          for neurons_prev in range(layer.weights.shape[0]):\n",
        "            for neurons_next in range(layer.weights.shape[1]):\n",
        "              \n",
        "              epsilon = np.zeros(layer.weights.shape)\n",
        "              epsilon[neurons_prev, neurons_next] = e\n",
        "\n",
        "              cost = []\n",
        "\n",
        "              #in first iteration add the epsilon value and calculate cost\n",
        "              #in second iteartion subtract the epsilon value and calculate cost\n",
        "              for k in range (0, 2, 1):\n",
        "\n",
        "                if k==0:  \n",
        "                  layer.weights = grad_network[layer_name]['weights_ori'] + epsilon\n",
        "                  \n",
        "                #forward propagation\n",
        "                c, _ = self.forward_propagate(X, Y, train=False)\n",
        "\n",
        "                #store cost\n",
        "                cost.append(c/X.shape[0])\n",
        "\n",
        "              #calculate and store numerically calculated derivative\n",
        "              deriv_weights_num[neurons_prev, neurons_next] = (cost[0]-cost[1])/(2*e)\n",
        "        \n",
        "        #Calculate percentage difference\n",
        "        grad_network[layer_name]['deriv_weights_num'] = deriv_weights_num\n",
        "        grad_network[layer_name]['deriv_weights_diff_percentage'] =  np.abs(grad_network[layer_name]['deriv_weights_num'] - grad_network[layer_name]['deriv_weights_ori'])*100\n",
        "\n",
        "        #For Bias\n",
        "\n",
        "        layer.weights = grad_network[layer_name]['weights_ori']\n",
        "\n",
        "        for filter in range(layer.bias.shape[0]):\n",
        "          \n",
        "          epsilon = np.zeros(layer.bias.shape)\n",
        "          epsilon[filter] = e\n",
        "          \n",
        "          cost = []\n",
        "\n",
        "          #in first iteration add the epsilon value and calculate cost\n",
        "          #in second iteartion subtract the epsilon value and calculate cost\n",
        "          for k in range (0, 2, 1):\n",
        "\n",
        "            if k==0:  \n",
        "              layer.bias = grad_network[layer_name]['bias_ori'] + epsilon\n",
        "                  \n",
        "            else:\n",
        "              layer.bias = grad_network[layer_name]['bias_ori'] - epsilon\n",
        "\n",
        "        \n",
        "            #forward propagation\n",
        "            c, _ = self.forward_propagate(X, Y, train=False)\n",
        "\n",
        "            #store cost\n",
        "            cost.append(c/X.shape[0])\n",
        "\n",
        "          #calculate and store numerically calculated derivative\n",
        "          deriv_bias_num[filter] = (cost[0]-cost[1])/(2*e)\n",
        "  \n",
        "        #Calculate percentage difference\n",
        "        grad_network[layer_name]['deriv_bias_num'] = deriv_bias_num\n",
        "        grad_network[layer_name]['deriv_bias_diff_percentage'] =  np.abs(grad_network[layer_name]['deriv_bias_num'] - grad_network[layer_name]['deriv_bias_ori'])*100\n",
        "        \n",
        "        layer.bias = grad_network[layer_name]['bias_ori']\n",
        "\n",
        "    #print the network for verification of derivative calculation\n",
        "    for p in grad_network:\n",
        "      print(f'{p}\\n')\n",
        "      for o in grad_network[p]:\n",
        "        print(f'{o}:\\n {grad_network[p][o]}\\n')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def train(self, data, train_batch_size, valid_batch_size, epcohs, lmbda, lr, grad_check=False):\n",
        "    '''\n",
        "      Performs training of the model and returns training and validation cost and accuracy for each iteration \n",
        "\n",
        "      Parameters:\n",
        "\n",
        "        data: object of class 'Dataset' \n",
        "          the data which will be used for training and validation\n",
        "        \n",
        "        train_batch_size: int \n",
        "          size of batch for training data. This determines the number of examples after which weights wiil be updated\n",
        "        \n",
        "        valid_batch_size: int \n",
        "          size of batch for validation data.  \n",
        "\n",
        "        epochs: int\n",
        "          number of times whole dataset needs to be passed through the network during training\n",
        "\n",
        "        lmbda: int or float\n",
        "          value of regulariztion parameter.\n",
        "        \n",
        "        lr: int or float\n",
        "          value of learning rate\n",
        "        \n",
        "        grad_check: bool\n",
        "          whether to calculate and check numerically calculated gradients with analytically calculated gradients\n",
        "\n",
        "      Notes:\n",
        "\n",
        "        - The optimizer algorithm uses L2 regularization.    \n",
        "\n",
        "    ''' \n",
        "\n",
        "    #temporary lists for storing the cost and accuracy values in each iteration  \n",
        "    train_cost_iter=[]\n",
        "    train_accu_iter=[]\n",
        "    valid_cost_iter=[]\n",
        "    valid_accu_iter=[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      for b in range (0, data.train_data.shape[0], train_batch_size): \n",
        "        \n",
        "        #Training\n",
        "\n",
        "        #load data\n",
        "        train_X,train_Y = data.load_data(flag='train', batch = [b, b + train_batch_size])\n",
        "        \n",
        "        #forward propagation\n",
        "        train_cost, train_accu = self.forward_propagate(train_X, train_Y, train=True)\n",
        "       \n",
        "        #store training cost and accuracy\n",
        "        train_cost_iter.append(train_cost/train_X.shape[0])\n",
        "        train_accu_iter.append((train_accu[0]/train_X.shape[0])*100) #Store Classification Accuary percentage\n",
        "\n",
        "        #back propagation\n",
        "        self.back_propagate()\n",
        "\n",
        "        #Estimate Gradient Numerically\n",
        "        #as this is a slow process, the code will run only for first batch and terminate\n",
        "        if grad_check:\n",
        "          self.gradient_check(train_X, train_Y)\n",
        "          break\n",
        "\n",
        "        #Valdiation\n",
        "\n",
        "        valid_cost=0\n",
        "        valid_accu=0\n",
        "        \n",
        "        for v in range(0, data.valid_data.shape[0], valid_batch_size):\n",
        "\n",
        "          valid_X, valid_Y = data.load_data (flag='valid', batch = [v, v + valid_batch_size] )\n",
        "\n",
        "          cost, accu = self.forward_propagate(valid_X, valid_Y, train=False)\n",
        "\n",
        "          valid_cost += cost\n",
        "          valid_accu += accu[0]\n",
        "\n",
        "        #store validation cost and accuracy\n",
        "        valid_cost_iter.append(valid_cost/data.valid_data.shape[0])\n",
        "        valid_accu_iter.append((valid_accu/data.valid_data.shape[0])*100)\n",
        "        \n",
        "        print('Epoch: ', epoch+1, '/', epochs, ' Iteration: ', int((b/train_batch_size)+1), ' Training Loss: ', train_cost/train_X.shape[0], ' Training Accuracy: ',\\\n",
        "               (train_accu[0]/train_X.shape[0])*100,  '%  Validation Loss: ', valid_cost/data.valid_data.shape[0], ' Validation Accuracy: ',\\\n",
        "               (valid_accu/data.valid_data.shape[0])*100, '%')\n",
        "\n",
        "        #update parameters\n",
        "        self.update_parameters(train_batch_size, lmbda, lr, iter=(b/train_batch_size)+1)\n",
        "      \n",
        "      if grad_check:\n",
        "        break\n",
        "\n",
        "    \n",
        "    return train_cost_iter, train_accu_iter, valid_cost_iter, valid_accu_iter  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9v0HE4z1rts"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytQ8sFNr10Dd"
      },
      "source": [
        "def plot_graph (x1, x2, legends, ylabel, title):\n",
        "  '''\n",
        "    Plots graph of 'x1' and 'x2' on same figure\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'x1': list of float\n",
        "        values for first graph\n",
        "      \n",
        "      'x2': list of float\n",
        "        values for second graph\n",
        "      \n",
        "      'legends': list of str\n",
        "        legend for each graph\n",
        "      \n",
        "      'ylabel': str\n",
        "        label for y-axis\n",
        "\n",
        "      'title': str\n",
        "        title of the graph\n",
        "    \n",
        "  '''\n",
        "  plt.plot(x1,  label=legends[0])\n",
        "  plt.plot(x2, label=legends[1])\n",
        "  plt.title(title)\n",
        "  plt.xlabel('Iterations')\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.legend()\n",
        "  plt.axis()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixXrA2pI09Z"
      },
      "source": [
        "def disp_F1_score(score, classes):\n",
        "  '''\n",
        "    displays Confusion Matrix and F1 table\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      score: list of numpy arrays\n",
        "        Confusion matrix on first index (shape=(number_of_classes, number_of_classes)) \n",
        "        and F1 table on second index (shape=(number of classes, 3))\n",
        "\n",
        "      labels: list\n",
        "        labels in dataset\n",
        "  '''\n",
        "  display(pd.DataFrame(score[0], columns=classes, index=classes))\n",
        "  display(pd.DataFrame(score[1], columns=['Precision', 'Recall', 'F1 score'], index=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpCBAyPdHuvh"
      },
      "source": [
        "def plot_weights(filters):\n",
        "  '''\n",
        "    Visualize weights in Convolutional Layer\n",
        "\n",
        "    Parameters:\n",
        "\n",
        "      'filters' : numpy array of shape (number_of_filters, channels, rows, cols)\n",
        "        weights associated with Convolution layer which need to be plotted\n",
        "  '''\n",
        "  count =1\n",
        "  #for each filter\n",
        "  for f in range(filters.shape[0]):\n",
        "    \n",
        "    #for each channel\n",
        "    for d in range(filters.shape[1]):\n",
        "     \n",
        "      plt.subplot(filters.shape[0], filters.shape[1], count)\n",
        "      plt.imshow(filters[f,d], cmap='gray')\n",
        "      \n",
        "      if not f>0:\n",
        "        plt.title('Channel ' + str(d+1))\n",
        "\n",
        "      if not d > 0:\n",
        "        plt.ylabel('Filter ' + str(f+1)) \n",
        "      \n",
        "      count += 1\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7nTLFEdTG0h"
      },
      "source": [
        "# Error Calculation on specified dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZLgsufqTGH7"
      },
      "source": [
        "def calculate_error(model, data, data_type):\n",
        " \n",
        "  '''\n",
        "    Calculates and displays loss, Classification Accuracy, Confusion Matrix and F1 score on specified dataset\n",
        "    \n",
        "    Parameters:\n",
        "\n",
        "      'model' : object of class 'Network'\n",
        "        trained model which will be used for making prediction\n",
        "\n",
        "      'data' : object of class 'Dataset'\n",
        "        same object of Dataset which was used for training the model\n",
        "\n",
        "      'data_type' : str 'train', 'valid' or 'test'\n",
        "        the data on which prediction needs to be carried out. It can take one of the three values.\n",
        "\n",
        "  '''\n",
        "  #Determine number of images\n",
        "  if data_type == 'train':\n",
        "    noOfimages = data.train_data.shape[0]\n",
        "  \n",
        "  elif data_type == 'valid':\n",
        "    noOfimages = data.valid_data.shape[0]\n",
        "  \n",
        "  elif data_type == 'test':\n",
        "    noOfimages = data.test_data.shape[0]\n",
        "  \n",
        "  else:\n",
        "    sys.exit(\"Invalid Value for parameter 'data_type'. It can only be 'train', 'test', or 'valid'\")\n",
        "  \n",
        "  batch_size = 512\n",
        "  total_cost = 0\n",
        "  total_accu = 0\n",
        "  confusion_matrix = np.zeros((len(data.labels), len(data.labels)))\n",
        "\n",
        "\n",
        "  for b in range (0, noOfimages, batch_size): \n",
        "\n",
        "    #load data\n",
        "    X, Y = data.load_data(flag='train', batch = [b, b + batch_size])\n",
        "    \n",
        "    #forward propagation\n",
        "    cost, accu = model.forward_propagate(X, Y, train=True)\n",
        "    \n",
        "    #store cost, classification accuracy and consfusion matrix\n",
        "    total_cost += cost\n",
        "    total_accu += accu[0]\n",
        "    confusion_matrix += accu [1]\n",
        "\n",
        "  #precision, recall and f1 score table\n",
        "  tab = np.zeros((len(data.labels), 3))\n",
        "  \n",
        "  for label in range(len(data.labels)):\n",
        "\n",
        "    TP = confusion_matrix[label,label] #true positive\n",
        "    FP = np.sum(confusion_matrix[label,:]) - TP #false positive\n",
        "    FN = np.sum(confusion_matrix[:,label]) - TP #false negative\n",
        "\n",
        "    #calculate F1 score\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "    tab[label] = np.array([precision, recall, f1])\n",
        "  \n",
        "  #Display results\n",
        "  print (\"The total cost on \", data_type, \" data is \", total_cost/noOfimages)\n",
        "  print(\"The Classification Accuracy on \", data_type, \" data is \", (total_accu/noOfimages)*100)\n",
        "  print()\n",
        "  disp_F1_score([confusion_matrix, tab], data.labels)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqn-X5YeakwI"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aj7WpvwMSfh"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUnjIOKYMU2Z"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EBAE3eHV_-B"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_mGI4pLx7mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a06afe8a-25df-4af4-f6a7-7a577bf519b2"
      },
      "source": [
        "path_to_data = '/content/drive/MyDrive/PBC_dataset_normal_DIB'\n",
        "#path_to_data= '/content/drive/MyDrive/test'\n",
        "data = Dataset(path_to_data, resize=(50,50), zero_center='image' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total  17092  images found with total  8  classes\n",
            "labels ['basophil', 'eosinophil', 'erythroblast', 'ig', 'lymphocyte', 'monocyte', 'neutrophil', 'platelet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cqVvuqInexL"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA7pQmwPx7mf"
      },
      "source": [
        "Conv4 = Conv(number_of_filters=4, filter_size=11, stride=1, zero_padding=1)\n",
        "LReLU4= LeakyReLU()\n",
        "Pool4= Pool('max', filter_size=2, stride=2)\n",
        "Conv8= Conv(number_of_filters=8, filter_size=3, stride=1, zero_padding=1)\n",
        "LReLU8= LeakyReLU()\n",
        "Pool8= Pool('max', filter_size=3, stride=2)\n",
        "FC200 = FC(neurons=200)\n",
        "LReLU200 = LeakyReLU()\n",
        "FC8 = FC(neurons=8)\n",
        "SM = Softmax ( )\n",
        "CE = CELoss (number_of_classes=8)\n",
        "layers=[Conv4, LReLU4, Pool4, Conv8, LReLU8, Pool8, FC200,LReLU200, FC8, SM, CE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITN2gflD4i1T"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bApv5FGlx7mg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb42d970-e67d-40ea-d955-bb8aa58d0547"
      },
      "source": [
        "#setting up hyperparameters\n",
        "weights_init='He'\n",
        "bias_init=0.01\n",
        "eval_metric = [ClassAccu, ConfMatrix]\n",
        "optimizer = AD( beta1=0.9, beta2=0.999)\n",
        "train_batch_size = 768\n",
        "valid_batch_size = 1024 \n",
        "epochs = 2\n",
        "lmbda = 0.001\n",
        "lr = 0.0001\n",
        "\n",
        "#train\n",
        "model=Network(layers=layers, weights_init=weights_init, bias_init=bias_init, optimizer=optimizer, eval_metric=eval_metric  )\n",
        "train_cost_iter, train_accu_iter, valid_cost_iter, valid_accu_iter = model.train(data, train_batch_size, valid_batch_size, epochs, lmbda, lr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1 / 2  Iteration:  1  Training Loss:  2.035872496256824  Training Accuracy:  11.328125 %  Validation Loss:  2.1608683576474523  Validation Accuracy:  11.146869514335869 %\n",
            "Epoch:  1 / 2  Iteration:  2  Training Loss:  2.2058761743686905  Training Accuracy:  7.03125 %  Validation Loss:  2.2181412807219223  Validation Accuracy:  11.936805149210064 %\n",
            "Epoch:  1 / 2  Iteration:  3  Training Loss:  2.1729819376152286  Training Accuracy:  8.723958333333332 %  Validation Loss:  2.2121213107913578  Validation Accuracy:  11.293153891164422 %\n",
            "Epoch:  1 / 2  Iteration:  4  Training Loss:  2.2002601338785848  Training Accuracy:  3.7760416666666665 %  Validation Loss:  2.145120461316103  Validation Accuracy:  11.322410766530135 %\n",
            "Epoch:  1 / 2  Iteration:  5  Training Loss:  2.0977143077253326  Training Accuracy:  10.546875 %  Validation Loss:  2.127564189691996  Validation Accuracy:  13.984786424809831 %\n",
            "Epoch:  1 / 2  Iteration:  6  Training Loss:  2.1005848051936553  Training Accuracy:  4.817708333333334 %  Validation Loss:  2.1343889635709408  Validation Accuracy:  12.814511410181392 %\n",
            "Epoch:  1 / 2  Iteration:  7  Training Loss:  2.2333682363847793  Training Accuracy:  8.203125 %  Validation Loss:  2.113219490808038  Validation Accuracy:  13.34113516676419 %\n",
            "Epoch:  1 / 2  Iteration:  8  Training Loss:  2.1397676217338812  Training Accuracy:  10.416666666666668 %  Validation Loss:  2.206598700354835  Validation Accuracy:  10.444704505558807 %\n",
            "Epoch:  1 / 2  Iteration:  9  Training Loss:  2.0990791027913227  Training Accuracy:  14.192708333333334 %  Validation Loss:  2.129626274069115  Validation Accuracy:  9.011117612638971 %\n",
            "Epoch:  1 / 2  Iteration:  10  Training Loss:  2.1594174169327554  Training Accuracy:  11.588541666666668 %  Validation Loss:  2.1050789014255735  Validation Accuracy:  16.12053832650673 %\n",
            "Epoch:  1 / 2  Iteration:  11  Training Loss:  2.062672416198593  Training Accuracy:  15.755208333333334 %  Validation Loss:  2.1199715171540183  Validation Accuracy:  14.306612053832652 %\n",
            "Epoch:  1 / 2  Iteration:  12  Training Loss:  2.1018164002692075  Training Accuracy:  15.104166666666666 %  Validation Loss:  2.1425124973809133  Validation Accuracy:  12.873025160912816 %\n",
            "Epoch:  1 / 2  Iteration:  13  Training Loss:  2.1437988414435565  Training Accuracy:  12.5 %  Validation Loss:  2.1326742806279393  Validation Accuracy:  15.974253949678175 %\n",
            "Epoch:  1 / 2  Iteration:  14  Training Loss:  2.0323683133728783  Training Accuracy:  20.66420664206642 %  Validation Loss:  2.1096412445566814  Validation Accuracy:  12.551199531889996 %\n",
            "Epoch:  2 / 2  Iteration:  1  Training Loss:  2.093619701761466  Training Accuracy:  14.192708333333334 %  Validation Loss:  2.144321912442748  Validation Accuracy:  12.375658279695728 %\n",
            "Epoch:  2 / 2  Iteration:  2  Training Loss:  2.09326248495836  Training Accuracy:  13.932291666666666 %  Validation Loss:  2.092099288104936  Validation Accuracy:  15.85722644821533 %\n",
            "Epoch:  2 / 2  Iteration:  3  Training Loss:  2.098108294311732  Training Accuracy:  14.713541666666666 %  Validation Loss:  2.1838152128244097  Validation Accuracy:  6.0561732007021645 %\n",
            "Epoch:  2 / 2  Iteration:  4  Training Loss:  2.0336518544329407  Training Accuracy:  17.578125 %  Validation Loss:  2.1792642625697045  Validation Accuracy:  8.07489760093622 %\n",
            "Epoch:  2 / 2  Iteration:  5  Training Loss:  2.1170999202336356  Training Accuracy:  16.927083333333336 %  Validation Loss:  2.1433942925088436  Validation Accuracy:  14.394382679929784 %\n",
            "Epoch:  2 / 2  Iteration:  6  Training Loss:  2.102894979136004  Training Accuracy:  5.729166666666666 %  Validation Loss:  2.118077040359203  Validation Accuracy:  12.112346401404329 %\n",
            "Epoch:  2 / 2  Iteration:  7  Training Loss:  2.0633844205692426  Training Accuracy:  16.796875 %  Validation Loss:  2.1766039444615055  Validation Accuracy:  17.875950848449385 %\n",
            "Epoch:  2 / 2  Iteration:  8  Training Loss:  2.05954850555756  Training Accuracy:  16.927083333333336 %  Validation Loss:  2.2040113354050157  Validation Accuracy:  11.117612638970158 %\n",
            "Epoch:  2 / 2  Iteration:  9  Training Loss:  2.25478947618358  Training Accuracy:  10.416666666666668 %  Validation Loss:  2.189089301950355  Validation Accuracy:  11.849034523112932 %\n",
            "Epoch:  2 / 2  Iteration:  10  Training Loss:  2.1561347225359495  Training Accuracy:  11.588541666666668 %  Validation Loss:  2.086521780014285  Validation Accuracy:  13.867758923346987 %\n",
            "Epoch:  2 / 2  Iteration:  11  Training Loss:  2.123312959687804  Training Accuracy:  13.020833333333334 %  Validation Loss:  2.195951531677645  Validation Accuracy:  8.42598010532475 %\n",
            "Epoch:  2 / 2  Iteration:  12  Training Loss:  2.1709055323562723  Training Accuracy:  9.635416666666668 %  Validation Loss:  2.0960696422755327  Validation Accuracy:  13.136337039204212 %\n",
            "Epoch:  2 / 2  Iteration:  13  Training Loss:  2.1948679036668923  Training Accuracy:  8.854166666666668 %  Validation Loss:  2.15120374862831  Validation Accuracy:  10.88355763604447 %\n",
            "Epoch:  2 / 2  Iteration:  14  Training Loss:  1.9822871207688744  Training Accuracy:  22.14022140221402 %  Validation Loss:  2.1401351689165113  Validation Accuracy:  12.141603276770041 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxoYcLNU44mG"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lkyZHgJ5HRX"
      },
      "source": [
        "###  Loss vs Iteration "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zf8Y_A-V4-W7",
        "outputId": "2b902771-cff6-47c3-9de1-fa2eaf4f6863"
      },
      "source": [
        "plot_graph(train_cost_iter, valid_cost_iter, legends= ['Training', 'Validation'], ylabel= 'Cost', title = 'Changes in Loss with each Iteration' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6G1mINc7M5L"
      },
      "source": [
        "### Classification Accuarcy vs Iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "INqBcZmP7bvd",
        "outputId": "a73ead14-504d-4f7d-cb03-7846013c7645"
      },
      "source": [
        "plot_graph(train_accu_iter, valid_accu_iter, legends= ['Training', 'Validation'], ylabel= 'Classification Accuracy', title = 'Evaluation of Model on Classification Accuracy (error metric)' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJqOZ3Ot19Ve"
      },
      "source": [
        "## Optimal Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymBI3cBK-n02",
        "outputId": "24ec7b52-e9ed-4685-a92c-8dfc684adfba"
      },
      "source": [
        "print(\"For Convolutional layer, the shape of weights is (number of filters, channels, rows, columns)\")\n",
        "print(\"and of bias is (number of filters, 1).\")\n",
        "print()\n",
        "print(\"For Fully Connected layer, the shape of weights is (number of neurons in previous layer, number of neurons in this layer)\")\n",
        "print(\" and of bias is (number of neurons in this layer, 1).\")\n",
        "\n",
        "conv_counter = 1\n",
        "fc_counter = 1\n",
        "for layer in model.layers:\n",
        "    if type(layer).__name__ == 'Conv':\n",
        "      print(\"Convolutional Layer \", conv_counter)\n",
        "      print()\n",
        "      print(\"Weights: \")\n",
        "      print(layer.weights)\n",
        "      print(\"Bias \")\n",
        "      print(layer.bias)\n",
        "      print()\n",
        "      conv_counter +=1\n",
        "    \n",
        "    if type(layer).__name__ == 'FC':\n",
        "      print(\"Fully Connected Layer \", fc_counter)\n",
        "      print()\n",
        "      print(\"Weights: \")\n",
        "      print(layer.weights)\n",
        "      print(\"Bias \")\n",
        "      print(layer.bias)\n",
        "      print()\n",
        "      fc_counter +=1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Convolutional layer, the shape of weights is (number of filters, channels, rows, columns)\n",
            "and of bias is (number of filters, 1).\n",
            "\n",
            "For Fully Connected layer, the shape of weights is (number of neurons in previous layer, number of neurons in this layer)\n",
            " and of bias is (number of neurons in this layer, 1).\n",
            "Convolutional Layer  1\n",
            "\n",
            "Weights: \n",
            "[[[[-8.33488271e-02 -2.97345604e-02  4.61594951e-02 ... -7.89583948e-02\n",
            "     1.31755442e-01  3.06162566e-02]\n",
            "   [-7.23874266e-02 -2.76895101e-02  3.43670568e-02 ... -1.39502015e-01\n",
            "    -1.11153517e-01  9.67548618e-02]\n",
            "   [ 1.26862430e-02 -1.37456572e-01 -1.33856754e-02 ... -5.19004124e-02\n",
            "     6.63019991e-02 -8.07791729e-02]\n",
            "   ...\n",
            "   [ 8.94373106e-03 -4.44073056e-02 -4.24144495e-02 ... -2.10930300e-01\n",
            "    -6.95054239e-02 -1.51852640e-01]\n",
            "   [ 8.33296796e-02 -2.00134529e-03 -1.11631738e-01 ... -7.57669094e-02\n",
            "     5.66759322e-02 -3.97555630e-02]\n",
            "   [ 6.03704184e-03  2.16120773e-01 -7.08612437e-02 ... -8.94866818e-02\n",
            "    -3.32949509e-02  1.93501539e-02]]\n",
            "\n",
            "  [[-2.46786634e-02  7.87770367e-02  2.07301312e-01 ...  1.57541515e-02\n",
            "     1.13776931e-02  3.65852929e-02]\n",
            "   [-1.03467604e-01  5.25662168e-02 -3.78203325e-02 ...  4.52667538e-02\n",
            "    -8.96355396e-02  5.93216430e-02]\n",
            "   [-5.93656043e-02 -1.01046688e-02 -8.28502429e-02 ...  1.65521312e-04\n",
            "     6.33073445e-02  3.02065355e-02]\n",
            "   ...\n",
            "   [-5.33455215e-02  2.41469847e-02 -1.35400471e-02 ...  1.05839605e-01\n",
            "    -1.09534121e-01  5.17744087e-02]\n",
            "   [-1.64963617e-01 -3.85870953e-04 -2.64383043e-02 ... -2.29535829e-02\n",
            "    -2.10018269e-01 -5.59796739e-03]\n",
            "   [-6.89505878e-02 -8.55177034e-02 -2.22390511e-02 ... -1.21831770e-01\n",
            "     3.98427763e-02  1.28565072e-01]]\n",
            "\n",
            "  [[-9.06963291e-02  8.37515565e-02  6.26969242e-02 ... -7.23612489e-02\n",
            "     1.67537259e-02 -6.66173024e-02]\n",
            "   [ 1.01311556e-01  1.45176016e-02 -2.25337601e-01 ...  1.33523613e-01\n",
            "    -3.70464419e-02 -1.12648320e-03]\n",
            "   [ 4.80633761e-02 -7.44066081e-02 -3.81631610e-02 ...  1.75902423e-02\n",
            "    -3.27154616e-02 -5.10947232e-02]\n",
            "   ...\n",
            "   [-5.73871242e-02  1.15536871e-01 -1.76393093e-02 ... -2.03085171e-02\n",
            "    -3.31704086e-02  1.81841646e-02]\n",
            "   [-1.30790320e-01  1.82900164e-02  3.58297081e-02 ...  4.01319985e-02\n",
            "     3.79123260e-02 -1.42850229e-02]\n",
            "   [-6.50003929e-02 -2.84567531e-02  3.49182209e-03 ... -2.74835212e-02\n",
            "    -9.22042198e-02  1.03703593e-02]]]\n",
            "\n",
            "\n",
            " [[[ 1.72611995e-02 -8.11775841e-03  1.17194498e-01 ... -2.82167700e-02\n",
            "    -3.31703516e-02 -1.05220891e-01]\n",
            "   [ 1.18739843e-02  3.91756049e-02  2.07302985e-03 ... -1.83829446e-02\n",
            "     4.35807609e-03 -1.02147652e-01]\n",
            "   [-1.50567233e-01  5.11312252e-02  2.88268210e-02 ... -8.21092317e-02\n",
            "     5.12804989e-05  4.44077424e-02]\n",
            "   ...\n",
            "   [ 2.89881551e-03 -1.08301098e-01 -7.52676090e-02 ...  5.55296593e-02\n",
            "     2.41435044e-02 -2.24959043e-02]\n",
            "   [-5.70482027e-02  4.38204204e-03 -8.04346155e-02 ... -1.88884634e-02\n",
            "    -2.35299341e-02  1.87098299e-02]\n",
            "   [ 4.49641963e-02 -1.55845334e-01  6.44046775e-02 ... -2.86403516e-02\n",
            "    -5.33491638e-02 -3.44872113e-02]]\n",
            "\n",
            "  [[ 3.40173871e-02 -1.25833242e-02 -5.08304360e-02 ... -9.90322594e-02\n",
            "    -3.96937972e-04 -7.55362418e-02]\n",
            "   [-3.51644361e-02 -3.08297187e-02 -3.03757709e-02 ...  2.59088226e-02\n",
            "    -6.76126521e-02 -2.09654892e-02]\n",
            "   [-7.92142814e-02 -8.87025131e-02 -1.56151247e-02 ... -9.89623212e-02\n",
            "     5.80226102e-03  4.47680069e-02]\n",
            "   ...\n",
            "   [-1.10403060e-01  9.46747587e-03 -1.36446118e-01 ...  7.13693277e-02\n",
            "    -7.68027404e-02 -3.17903031e-02]\n",
            "   [ 1.03114583e-01 -3.19361519e-02 -1.41132704e-01 ... -1.17066230e-01\n",
            "     4.25210461e-02 -5.64950245e-02]\n",
            "   [ 4.72231988e-03 -1.42088464e-02 -8.60480583e-02 ... -4.94556400e-02\n",
            "    -2.01659837e-02  1.41526735e-01]]\n",
            "\n",
            "  [[ 4.28717913e-04 -4.94706959e-02 -7.98159903e-02 ... -8.42366717e-02\n",
            "     3.44024422e-03  7.76235809e-02]\n",
            "   [ 4.35669300e-02 -7.04042353e-02  2.09535650e-01 ...  1.11401281e-01\n",
            "    -1.06235847e-01 -7.22711755e-02]\n",
            "   [-1.33862954e-01  7.31194037e-02 -1.12756815e-01 ... -2.06134462e-02\n",
            "     6.56782003e-02 -7.45920681e-02]\n",
            "   ...\n",
            "   [ 8.27198780e-02 -3.78974617e-02  1.07335821e-01 ...  5.87622844e-02\n",
            "     2.79625778e-02 -8.79051911e-02]\n",
            "   [ 8.63162467e-02  8.92401412e-02  6.86992133e-02 ...  9.39490921e-02\n",
            "    -8.65344300e-03 -7.46084918e-02]\n",
            "   [ 2.71964645e-01 -6.21337516e-02  1.20437748e-01 ... -4.35963635e-03\n",
            "     1.13417000e-01 -8.19390661e-02]]]\n",
            "\n",
            "\n",
            " [[[-3.95043428e-02 -2.94118064e-03  2.44649415e-02 ...  6.22635432e-02\n",
            "     3.57314220e-02 -3.50701440e-02]\n",
            "   [-3.12267431e-02 -2.32412414e-03  2.39969763e-02 ...  4.36640978e-02\n",
            "     6.62281130e-02 -1.23953293e-01]\n",
            "   [-1.94561023e-02 -5.95229505e-02  8.16704715e-02 ... -7.35233011e-02\n",
            "    -1.29866726e-01  8.37783657e-02]\n",
            "   ...\n",
            "   [-1.44835223e-01 -6.72363509e-02 -2.61918503e-02 ... -6.11345509e-02\n",
            "     3.44459812e-02 -7.62316367e-02]\n",
            "   [ 2.47945308e-02 -1.12603221e-01  4.91216266e-04 ... -2.78610751e-02\n",
            "    -5.15387060e-02  4.83616964e-02]\n",
            "   [-1.71436290e-01  4.61887548e-02 -1.02860240e-01 ... -1.38276784e-01\n",
            "    -1.09026189e-01  2.91370289e-03]]\n",
            "\n",
            "  [[-3.24404485e-02 -2.75681115e-02 -8.27919918e-03 ... -1.07859484e-01\n",
            "     2.59225245e-02  7.19789077e-02]\n",
            "   [-1.22231157e-01  3.07326274e-02  2.70678197e-02 ... -6.79225532e-02\n",
            "    -2.90599129e-02  1.48195125e-01]\n",
            "   [ 5.69905823e-02 -5.53074183e-02 -5.77365605e-02 ... -6.56877293e-02\n",
            "     2.58545666e-02  1.12897985e-01]\n",
            "   ...\n",
            "   [-1.77889234e-01 -5.86097255e-02  5.54132656e-02 ... -8.14290761e-03\n",
            "     3.68337108e-02 -2.37400509e-02]\n",
            "   [-1.18043471e-01  1.24767068e-01  4.48093365e-02 ...  6.57181581e-02\n",
            "    -7.81174244e-02 -7.81662460e-02]\n",
            "   [-1.79253012e-02 -8.45911320e-02 -2.73021358e-02 ...  2.73543530e-02\n",
            "    -1.70673786e-02 -6.32945455e-03]]\n",
            "\n",
            "  [[ 9.22754326e-02 -8.91877446e-02 -8.05248868e-02 ...  1.01744415e-01\n",
            "    -1.09512511e-01 -6.12280504e-02]\n",
            "   [ 4.15680101e-02  1.00738513e-02 -4.27642995e-02 ... -7.07491893e-02\n",
            "    -5.23680751e-02 -4.44301299e-02]\n",
            "   [-2.50207046e-02  3.38959216e-02 -3.40358429e-02 ...  5.27507000e-03\n",
            "    -2.71336977e-02  4.27507155e-02]\n",
            "   ...\n",
            "   [ 5.40809785e-02 -1.17392203e-03  2.32458174e-02 ...  1.03897545e-01\n",
            "    -2.95401821e-02 -4.34897534e-02]\n",
            "   [ 9.10537764e-02 -9.99133666e-04  8.67647005e-03 ...  9.65449942e-02\n",
            "    -2.47635495e-02 -3.31138395e-02]\n",
            "   [ 1.18991774e-02  1.78944677e-01 -7.94710869e-02 ...  1.42426857e-01\n",
            "     2.37333207e-02  7.08742080e-03]]]\n",
            "\n",
            "\n",
            " [[[ 2.57992188e-02 -5.74862312e-02  2.41548823e-03 ...  4.40329148e-02\n",
            "    -1.20860533e-02 -4.58966976e-02]\n",
            "   [-6.09550240e-02 -1.14992502e-01 -4.56975055e-02 ...  6.25748534e-02\n",
            "    -9.00165091e-03 -1.87975079e-02]\n",
            "   [ 1.02297560e-01  8.56482712e-02  1.12822563e-01 ... -7.47597071e-02\n",
            "     4.71967141e-02 -1.78453867e-02]\n",
            "   ...\n",
            "   [-1.00468248e-01  4.46085461e-02 -6.97392732e-02 ... -3.55833160e-02\n",
            "    -1.55813521e-01  2.54181491e-02]\n",
            "   [-2.75127951e-02 -9.67808623e-02 -1.10191438e-01 ...  1.50132738e-01\n",
            "     2.73193668e-02  6.58625976e-02]\n",
            "   [-1.17922327e-01 -7.11211788e-02 -2.07835111e-02 ... -7.91453108e-03\n",
            "     5.30813924e-02 -8.29268019e-02]]\n",
            "\n",
            "  [[-7.92088580e-02 -4.94345380e-02  6.44189763e-03 ... -5.80489497e-02\n",
            "     2.79059214e-02  1.87231669e-02]\n",
            "   [ 1.32987103e-01  1.06013743e-01  7.55946524e-02 ...  8.35415783e-02\n",
            "    -1.19649613e-02 -8.49087701e-02]\n",
            "   [-7.40913835e-02  1.21618391e-01 -4.27431462e-02 ... -8.04614518e-02\n",
            "    -2.49780525e-02  6.46950359e-03]\n",
            "   ...\n",
            "   [-3.11592479e-03  1.37258927e-01 -1.56474436e-02 ...  8.36705754e-03\n",
            "    -6.26771854e-02 -5.31282111e-02]\n",
            "   [ 1.01597758e-01 -1.38248062e-02  8.71290195e-02 ... -1.92256460e-02\n",
            "    -1.16030207e-01 -7.00919794e-04]\n",
            "   [ 4.71470790e-02 -5.74798330e-02 -1.60003802e-02 ...  1.79253635e-02\n",
            "     1.52020744e-01 -2.01599673e-02]]\n",
            "\n",
            "  [[-4.87847909e-02 -2.29999320e-02 -6.74719719e-02 ... -1.84558098e-02\n",
            "    -1.03905579e-01 -2.74074957e-02]\n",
            "   [ 7.97206601e-02  1.29623621e-01  6.63347054e-03 ... -2.80796194e-02\n",
            "     2.20117891e-02 -5.78689812e-02]\n",
            "   [ 6.31251016e-02 -6.39548412e-02  6.59927736e-02 ... -1.92193822e-02\n",
            "     6.67453053e-03 -6.69814040e-02]\n",
            "   ...\n",
            "   [ 5.27870377e-03 -1.08056194e-02  2.15826172e-02 ...  3.14021347e-03\n",
            "     6.03974937e-02  2.12941096e-03]\n",
            "   [ 1.83300469e-03 -8.65197788e-02 -1.26805934e-01 ... -7.34589189e-03\n",
            "     2.44051822e-03 -4.73418639e-02]\n",
            "   [-8.80615692e-03 -3.08996282e-02  1.05918457e-01 ...  8.64033220e-03\n",
            "     2.10770368e-01 -1.89608611e-01]]]]\n",
            "Bias \n",
            "[[0.01003384]\n",
            " [0.01000466]\n",
            " [0.00999726]\n",
            " [0.00998804]]\n",
            "\n",
            "Convolutional Layer  2\n",
            "\n",
            "Weights: \n",
            "[[[[-3.19437628e-01  1.51887302e-01  2.73432872e-01]\n",
            "   [-1.49419113e-02 -4.69385286e-02 -4.65149658e-02]\n",
            "   [ 3.07736301e-01 -7.13716403e-02  2.61817786e-01]]\n",
            "\n",
            "  [[ 3.74854534e-02  3.54292246e-01 -2.62752967e-01]\n",
            "   [-1.47265091e-01  3.06080633e-02  3.25279241e-02]\n",
            "   [-7.92309272e-02  2.64322159e-01 -2.28876394e-01]]\n",
            "\n",
            "  [[-1.44085854e-01 -4.46422493e-01  3.63623683e-01]\n",
            "   [ 2.18060436e-01 -2.76600721e-01 -2.59461756e-01]\n",
            "   [ 1.10022119e-01 -2.70161573e-02  2.51849031e-02]]\n",
            "\n",
            "  [[ 6.52031913e-02  4.91717531e-01  8.45600076e-02]\n",
            "   [ 1.03149576e-01  4.66660109e-01 -1.52811243e-01]\n",
            "   [ 1.44621513e-01  7.76808072e-02  6.27014743e-01]]]\n",
            "\n",
            "\n",
            " [[[ 9.76216903e-02  2.58679129e-01  2.72072926e-01]\n",
            "   [ 2.29030859e-01 -8.74565888e-02  1.42363059e-01]\n",
            "   [ 4.98150923e-01 -1.50570713e-01  7.44883504e-02]]\n",
            "\n",
            "  [[ 2.73210859e-02 -6.64402073e-02  3.69972835e-01]\n",
            "   [ 1.23615845e-02 -1.85242149e-01 -3.91013890e-01]\n",
            "   [-6.87363774e-02  5.24932575e-01  2.89600361e-01]]\n",
            "\n",
            "  [[ 4.95500729e-02 -5.28145493e-02 -1.08744642e-01]\n",
            "   [ 7.80847525e-02 -4.98174499e-01  1.42160081e-01]\n",
            "   [ 3.39001424e-01 -6.11815655e-02 -6.06345288e-02]]\n",
            "\n",
            "  [[ 6.94116014e-02  6.71912448e-02 -9.48112375e-02]\n",
            "   [ 2.30614920e-01  2.06395373e-01 -3.94455708e-02]\n",
            "   [-3.65901966e-01  3.48109642e-02  1.72600199e-02]]]\n",
            "\n",
            "\n",
            " [[[-1.84839570e-01 -2.84656675e-01  9.85789021e-02]\n",
            "   [ 1.84728454e-01  1.33371651e-01  7.09206178e-02]\n",
            "   [-2.57606915e-01  1.42607755e-01  6.17837277e-02]]\n",
            "\n",
            "  [[-2.34768079e-01 -8.02588182e-02  3.69515566e-01]\n",
            "   [ 1.29109328e-01  3.81490943e-02  1.69625153e-01]\n",
            "   [-1.88223021e-01  4.28601738e-01  6.14890033e-02]]\n",
            "\n",
            "  [[ 6.05479482e-01 -2.90236115e-02  1.61073272e-01]\n",
            "   [-3.27523723e-01 -1.38374415e-01 -2.34655320e-01]\n",
            "   [ 1.04375603e-01 -3.42671108e-01  1.09722850e-01]]\n",
            "\n",
            "  [[-2.19101616e-01  9.27099953e-02 -6.54974208e-02]\n",
            "   [ 9.63782782e-02 -1.52147159e-01  6.97260499e-02]\n",
            "   [ 3.03887793e-01  2.45561875e-01 -2.84260105e-02]]]\n",
            "\n",
            "\n",
            " [[[-2.06053534e-01 -3.74287556e-01 -1.53874907e-01]\n",
            "   [-5.63858374e-02  1.41831253e-01 -3.38035456e-01]\n",
            "   [ 1.93359363e-01 -2.44768330e-01  2.61431464e-01]]\n",
            "\n",
            "  [[ 3.96952818e-02 -2.24893805e-01 -3.03824579e-01]\n",
            "   [-5.45683644e-02 -2.85592005e-01  3.19849878e-02]\n",
            "   [ 2.90552247e-02 -4.39752238e-02  3.24339513e-01]]\n",
            "\n",
            "  [[-4.65519337e-02 -4.14154848e-02  9.63542918e-02]\n",
            "   [ 2.84185089e-01 -1.56587920e-01 -5.29947863e-02]\n",
            "   [ 1.14900651e-02  2.28746620e-02 -3.05685135e-02]]\n",
            "\n",
            "  [[ 9.33110636e-03  1.32921046e-01  2.36833192e-01]\n",
            "   [-2.43852171e-01 -3.76635086e-02 -1.54307338e-01]\n",
            "   [ 1.53201518e-02 -8.61469497e-02  3.64251593e-01]]]\n",
            "\n",
            "\n",
            " [[[ 1.06264535e-02  3.86429499e-02 -5.50084656e-02]\n",
            "   [-2.37432223e-01  4.34289840e-01 -3.32032514e-01]\n",
            "   [ 1.79653910e-01  1.41962815e-01 -2.37113909e-01]]\n",
            "\n",
            "  [[ 7.39003811e-02  3.67489292e-01  4.40010625e-01]\n",
            "   [ 1.49629303e-01  1.33257884e-01 -3.02906372e-01]\n",
            "   [-4.93075255e-02  1.49739064e-02 -6.52088311e-02]]\n",
            "\n",
            "  [[ 2.36409660e-01 -6.98334511e-02  3.24887295e-02]\n",
            "   [ 1.49682308e-01  1.77447513e-01  3.26102127e-01]\n",
            "   [ 1.09239408e-02  3.00892034e-01  2.51973739e-01]]\n",
            "\n",
            "  [[-3.08692815e-01  4.71186702e-01 -4.03781831e-01]\n",
            "   [ 2.63814866e-01 -4.78729376e-02  6.81103022e-02]\n",
            "   [-6.76829288e-01 -1.33087395e-01  2.03267281e-01]]]\n",
            "\n",
            "\n",
            " [[[-4.88811413e-03 -2.24975073e-01 -9.15453866e-02]\n",
            "   [-3.18890467e-01 -1.68595135e-01 -5.62223564e-02]\n",
            "   [-1.78690395e-01  1.63186337e-01 -4.80717447e-01]]\n",
            "\n",
            "  [[ 6.06631976e-01 -2.40070143e-01  6.35012224e-02]\n",
            "   [ 1.91306824e-01 -1.30821485e-01  1.43732029e-04]\n",
            "   [-1.89641212e-01  1.34086338e-02  8.34974478e-02]]\n",
            "\n",
            "  [[-1.57069472e-01  7.89705996e-01 -2.41364027e-01]\n",
            "   [ 3.76715721e-01 -4.96706544e-01  1.32286967e-02]\n",
            "   [ 7.37582226e-02  3.78815078e-01 -1.62373788e-01]]\n",
            "\n",
            "  [[ 3.26125287e-02  7.94876507e-02  6.96980037e-02]\n",
            "   [-3.17288334e-02 -1.19308623e-01 -6.18972316e-01]\n",
            "   [-2.94671777e-01  7.03273419e-02 -7.97655174e-02]]]\n",
            "\n",
            "\n",
            " [[[ 2.66492682e-01  1.70090692e-01 -7.37293385e-02]\n",
            "   [ 6.91884955e-02 -1.96820523e-01  2.63532744e-01]\n",
            "   [ 1.42010205e-01 -9.36317002e-02  4.64566913e-01]]\n",
            "\n",
            "  [[-2.84571374e-01  3.47213967e-01  4.59282333e-02]\n",
            "   [-2.10075450e-01  2.61443063e-01 -2.71388515e-01]\n",
            "   [ 6.70377337e-01 -4.61654627e-01  1.30310393e-01]]\n",
            "\n",
            "  [[-5.88088219e-02  1.11918546e-01 -3.61676792e-01]\n",
            "   [-1.04196592e-01  1.44254275e-01  2.58908702e-01]\n",
            "   [-1.23935867e-01  4.84950053e-01  1.21461657e-01]]\n",
            "\n",
            "  [[-1.90146678e-01  1.78673664e-01  3.23585192e-01]\n",
            "   [ 1.00236322e-01  9.49150405e-02  2.46388484e-01]\n",
            "   [-1.59667225e-01  1.99858283e-01 -2.05183421e-01]]]\n",
            "\n",
            "\n",
            " [[[-2.17991515e-01  1.92775852e-01 -2.48400635e-01]\n",
            "   [-1.00703709e-01 -2.94461550e-02 -1.47462054e-02]\n",
            "   [ 6.24190381e-02  4.81792555e-01 -1.87342419e-01]]\n",
            "\n",
            "  [[-1.57813340e-01  3.10927763e-01  4.69304410e-01]\n",
            "   [ 3.76888215e-01 -2.92525064e-02  3.88957205e-02]\n",
            "   [ 2.54960617e-01  3.95456329e-02 -5.35307496e-02]]\n",
            "\n",
            "  [[ 1.35052989e-01  8.68772020e-02  2.26779111e-01]\n",
            "   [-1.42417703e-01 -4.40997147e-02  5.05924152e-01]\n",
            "   [-2.93987625e-01  3.14443944e-01  1.88953300e-01]]\n",
            "\n",
            "  [[ 6.49898321e-02  2.60557562e-01  3.82448341e-01]\n",
            "   [-2.92636021e-02  1.56673188e-01 -7.02969550e-02]\n",
            "   [-1.66876338e-01  1.98544580e-01  3.18278091e-01]]]]\n",
            "Bias \n",
            "[[0.00996094]\n",
            " [0.01001737]\n",
            " [0.009992  ]\n",
            " [0.01000278]\n",
            " [0.01002962]\n",
            " [0.00997419]\n",
            " [0.01001035]\n",
            " [0.00996649]]\n",
            "\n",
            "Fully Connected Layer  1\n",
            "\n",
            "Weights: \n",
            "[[-0.01889884 -0.00140161  0.03723653 ...  0.04625886 -0.05518495\n",
            "  -0.01727244]\n",
            " [-0.03970295 -0.09522164 -0.0343462  ...  0.01403097 -0.01062918\n",
            "  -0.03210855]\n",
            " [-0.09088627  0.00602864 -0.07250967 ... -0.06089552 -0.03252846\n",
            "  -0.07263338]\n",
            " ...\n",
            " [ 0.00256053 -0.08309645 -0.03595374 ...  0.00133249  0.00418808\n",
            "  -0.01221144]\n",
            " [-0.00151414  0.00870346 -0.01901106 ...  0.04882231  0.04037555\n",
            "  -0.03298408]\n",
            " [-0.04217263 -0.04357504  0.02436396 ...  0.02522861  0.03736883\n",
            "   0.11613293]]\n",
            "Bias \n",
            "[[0.0100136 ]\n",
            " [0.00999397]\n",
            " [0.00998388]\n",
            " [0.01000177]\n",
            " [0.01001068]\n",
            " [0.00998791]\n",
            " [0.01003352]\n",
            " [0.01001114]\n",
            " [0.01000064]\n",
            " [0.01001164]\n",
            " [0.00999851]\n",
            " [0.01001956]\n",
            " [0.01003751]\n",
            " [0.01001483]\n",
            " [0.00997863]\n",
            " [0.00997979]\n",
            " [0.01000044]\n",
            " [0.01000022]\n",
            " [0.00999043]\n",
            " [0.0100059 ]\n",
            " [0.01002389]\n",
            " [0.01001481]\n",
            " [0.00995834]\n",
            " [0.00999338]\n",
            " [0.01001521]\n",
            " [0.01003175]\n",
            " [0.01001863]\n",
            " [0.00999367]\n",
            " [0.00999928]\n",
            " [0.01002861]\n",
            " [0.01001996]\n",
            " [0.01000308]\n",
            " [0.0100113 ]\n",
            " [0.0099981 ]\n",
            " [0.01001468]\n",
            " [0.00997536]\n",
            " [0.00995377]\n",
            " [0.00998264]\n",
            " [0.00999681]\n",
            " [0.00999859]\n",
            " [0.00999248]\n",
            " [0.00997949]\n",
            " [0.00998801]\n",
            " [0.00998316]\n",
            " [0.00999907]\n",
            " [0.00997849]\n",
            " [0.01000587]\n",
            " [0.01000679]\n",
            " [0.01001659]\n",
            " [0.01001368]\n",
            " [0.00999152]\n",
            " [0.01002025]\n",
            " [0.01000879]\n",
            " [0.00998147]\n",
            " [0.00997687]\n",
            " [0.00999185]\n",
            " [0.01003504]\n",
            " [0.01000095]\n",
            " [0.00995549]\n",
            " [0.01001819]\n",
            " [0.00998933]\n",
            " [0.00999581]\n",
            " [0.00998864]\n",
            " [0.01000959]\n",
            " [0.01000585]\n",
            " [0.00998398]\n",
            " [0.01003832]\n",
            " [0.01002146]\n",
            " [0.00997431]\n",
            " [0.01002274]\n",
            " [0.00996171]\n",
            " [0.00998783]\n",
            " [0.00998324]\n",
            " [0.00999951]\n",
            " [0.00999571]\n",
            " [0.01000353]\n",
            " [0.01003646]\n",
            " [0.01002285]\n",
            " [0.00999406]\n",
            " [0.01000374]\n",
            " [0.00997412]\n",
            " [0.01003297]\n",
            " [0.01000456]\n",
            " [0.00998069]\n",
            " [0.01003234]\n",
            " [0.01000275]\n",
            " [0.00999371]\n",
            " [0.00999434]\n",
            " [0.0099818 ]\n",
            " [0.01000537]\n",
            " [0.01004689]\n",
            " [0.01001905]\n",
            " [0.00998322]\n",
            " [0.01002711]\n",
            " [0.01001319]\n",
            " [0.01001123]\n",
            " [0.00998227]\n",
            " [0.0100064 ]\n",
            " [0.00998997]\n",
            " [0.01000847]\n",
            " [0.01000038]\n",
            " [0.00996642]\n",
            " [0.00998948]\n",
            " [0.00999832]\n",
            " [0.00999164]\n",
            " [0.01001517]\n",
            " [0.01001345]\n",
            " [0.00998812]\n",
            " [0.0099901 ]\n",
            " [0.00998504]\n",
            " [0.00999013]\n",
            " [0.01003502]\n",
            " [0.01000634]\n",
            " [0.01000746]\n",
            " [0.01000496]\n",
            " [0.00996536]\n",
            " [0.00998729]\n",
            " [0.00997274]\n",
            " [0.01001679]\n",
            " [0.01001249]\n",
            " [0.00997383]\n",
            " [0.00998698]\n",
            " [0.01003379]\n",
            " [0.01002252]\n",
            " [0.01001365]\n",
            " [0.00998162]\n",
            " [0.01001588]\n",
            " [0.01000219]\n",
            " [0.0099738 ]\n",
            " [0.00996089]\n",
            " [0.00998608]\n",
            " [0.00998262]\n",
            " [0.01000206]\n",
            " [0.01000157]\n",
            " [0.00999022]\n",
            " [0.00997173]\n",
            " [0.0100335 ]\n",
            " [0.01004107]\n",
            " [0.00999864]\n",
            " [0.01002931]\n",
            " [0.01001002]\n",
            " [0.00997739]\n",
            " [0.00997069]\n",
            " [0.00999814]\n",
            " [0.01002478]\n",
            " [0.01000363]\n",
            " [0.01004439]\n",
            " [0.01003577]\n",
            " [0.00997391]\n",
            " [0.00999568]\n",
            " [0.00998093]\n",
            " [0.00997873]\n",
            " [0.0099797 ]\n",
            " [0.01001522]\n",
            " [0.00994881]\n",
            " [0.00997206]\n",
            " [0.0099712 ]\n",
            " [0.01000131]\n",
            " [0.01001194]\n",
            " [0.00996941]\n",
            " [0.00997919]\n",
            " [0.00998804]\n",
            " [0.00999175]\n",
            " [0.0100107 ]\n",
            " [0.01002081]\n",
            " [0.00998528]\n",
            " [0.0099985 ]\n",
            " [0.00997685]\n",
            " [0.0099989 ]\n",
            " [0.0100109 ]\n",
            " [0.01000345]\n",
            " [0.00999889]\n",
            " [0.00999732]\n",
            " [0.00998979]\n",
            " [0.0099602 ]\n",
            " [0.01000236]\n",
            " [0.0099987 ]\n",
            " [0.00998836]\n",
            " [0.01000205]\n",
            " [0.00998983]\n",
            " [0.01000619]\n",
            " [0.01001938]\n",
            " [0.00999974]\n",
            " [0.0100209 ]\n",
            " [0.00999247]\n",
            " [0.00999733]\n",
            " [0.01000282]\n",
            " [0.01001599]\n",
            " [0.01000377]\n",
            " [0.01001279]\n",
            " [0.00999836]\n",
            " [0.01001492]\n",
            " [0.00996847]\n",
            " [0.0100198 ]\n",
            " [0.01002887]\n",
            " [0.01000886]\n",
            " [0.00999311]\n",
            " [0.01001575]\n",
            " [0.00997389]\n",
            " [0.01001118]]\n",
            "\n",
            "Fully Connected Layer  2\n",
            "\n",
            "Weights: \n",
            "[[ 0.07632025  0.00449002 -0.18065035 ...  0.12746361 -0.05322351\n",
            "   0.19070739]\n",
            " [ 0.00234704 -0.07748639  0.10126946 ... -0.26446566  0.09687472\n",
            "  -0.01641227]\n",
            " [ 0.04592095 -0.04390494  0.06209168 ...  0.11182549 -0.12441607\n",
            "  -0.04203934]\n",
            " ...\n",
            " [-0.0050665   0.05546982 -0.01602452 ...  0.11565836 -0.10715605\n",
            "  -0.09848084]\n",
            " [ 0.11497522 -0.24945098 -0.00230734 ... -0.04728483  0.11774931\n",
            "   0.18958065]\n",
            " [-0.12634727 -0.12972885  0.0649041  ...  0.00286689  0.07274253\n",
            "  -0.04556293]]\n",
            "Bias \n",
            "[[0.01008049]\n",
            " [0.01008268]\n",
            " [0.0100819 ]\n",
            " [0.01008169]\n",
            " [0.01008355]\n",
            " [0.01008164]\n",
            " [0.01008283]\n",
            " [0.01008134]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "wP1yDrNy8SsZ",
        "outputId": "4b5a9d35-4943-477a-fda1-5bda43389a10"
      },
      "source": [
        "conv_counter=1\n",
        "for layer in model.layers:\n",
        "  if type(layer).__name__ == 'Conv':\n",
        "    print(\"Filters of Convolutional Layer Number: \", conv_counter)\n",
        "\n",
        "    plot_weights(layer.weights)\n",
        "\n",
        "    conv_counter += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filters of Convolutional Layer Number:  1\n",
            "Filters of Convolutional Layer Number:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 32 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu_js9RU2KZ4"
      },
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEp5_qqCBDjR"
      },
      "source": [
        "### Data Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqugCkcH2QxZ"
      },
      "source": [
        "with open('/content/Model.npy', 'wb') as file:\n",
        "\n",
        "  np.save(file, data.resize) #save resizing of image\n",
        "\n",
        "  np.save(file, data.mean) #save zero centering info\n",
        "\n",
        "  np.save(file, data.labels) #save labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk6zauR5FEXs"
      },
      "source": [
        "### Architecture Properties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcNsuJY6FK4f"
      },
      "source": [
        "with open('/content/Model.npy', 'ab') as file:\n",
        "\n",
        "  #save layers except loss function\n",
        "  layers=[type(layer).__name__ for layer in model.layers[:-1]]\n",
        "  np.save(file,  layers) \n",
        "\n",
        "  #save parameters and other associated hyperparameters\n",
        "\n",
        "  for layer in model.layers[:-1]: #except loss function\n",
        " \n",
        "    if type(layer).__name__ == 'Conv':\n",
        "\n",
        "      np.save(file, layer.stride)\n",
        "      np.save(file, layer.zero_padding)\n",
        "      np.save(file, layer.weights)\n",
        "      np.save(file, layer.bias)\n",
        "    \n",
        "    if type(layer).__name__ == 'Pool':\n",
        "      \n",
        "      np.save(file, layer.pooling_type)\n",
        "      np.save(file, layer.filter_size)\n",
        "      np.save(file, layer.stride)\n",
        "      np.save(file, layer.zero_padding)\n",
        "    \n",
        "    if type(layer).__name__ == 'FC':\n",
        "      \n",
        "      np.save(file, layer.neurons)\n",
        "      np.save(file, layer.weights)\n",
        "      np.save(file, layer.bias)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0GtJkLj2b0K"
      },
      "source": [
        "## Error Metrics on Train, Validation and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDtOcxKb23Rf"
      },
      "source": [
        "### Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ7QApZY28Sd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "5731d617-0752-428b-995f-ea310705c89c"
      },
      "source": [
        "calculate_error(model, data, 'train')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total cost on  train  data is  2.137111176845495\n",
            "The Classification Accuracy on  train  data is  13.651877133105803\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>basophil</th>\n",
              "      <th>eosinophil</th>\n",
              "      <th>erythroblast</th>\n",
              "      <th>ig</th>\n",
              "      <th>lymphocyte</th>\n",
              "      <th>monocyte</th>\n",
              "      <th>neutrophil</th>\n",
              "      <th>platelet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>basophil</th>\n",
              "      <td>39.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eosinophil</th>\n",
              "      <td>93.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>erythroblast</th>\n",
              "      <td>168.0</td>\n",
              "      <td>421.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>149.0</td>\n",
              "      <td>218.0</td>\n",
              "      <td>419.0</td>\n",
              "      <td>275.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>129.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>151.0</td>\n",
              "      <td>414.0</td>\n",
              "      <td>266.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lymphocyte</th>\n",
              "      <td>60.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monocyte</th>\n",
              "      <td>96.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>247.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>269.0</td>\n",
              "      <td>204.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutrophil</th>\n",
              "      <td>48.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelet</th>\n",
              "      <td>86.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>334.0</td>\n",
              "      <td>269.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              basophil  eosinophil  ...  neutrophil  platelet\n",
              "basophil          39.0        60.0  ...        81.0      18.0\n",
              "eosinophil        93.0       259.0  ...       237.0     185.0\n",
              "erythroblast     168.0       421.0  ...       419.0     275.0\n",
              "ig               129.0       344.0  ...       414.0     266.0\n",
              "lymphocyte        60.0       163.0  ...       132.0     160.0\n",
              "monocyte          96.0       295.0  ...       269.0     204.0\n",
              "neutrophil        48.0       120.0  ...       130.0      24.0\n",
              "platelet          86.0       242.0  ...       334.0     269.0\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>basophil</th>\n",
              "      <td>0.101299</td>\n",
              "      <td>0.054242</td>\n",
              "      <td>0.070652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eosinophil</th>\n",
              "      <td>0.196958</td>\n",
              "      <td>0.136029</td>\n",
              "      <td>0.160920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>erythroblast</th>\n",
              "      <td>0.082589</td>\n",
              "      <td>0.201745</td>\n",
              "      <td>0.117200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>0.157617</td>\n",
              "      <td>0.173233</td>\n",
              "      <td>0.165057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lymphocyte</th>\n",
              "      <td>0.093240</td>\n",
              "      <td>0.110497</td>\n",
              "      <td>0.101138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monocyte</th>\n",
              "      <td>0.095928</td>\n",
              "      <td>0.163915</td>\n",
              "      <td>0.121027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutrophil</th>\n",
              "      <td>0.212418</td>\n",
              "      <td>0.064484</td>\n",
              "      <td>0.098935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelet</th>\n",
              "      <td>0.179453</td>\n",
              "      <td>0.192006</td>\n",
              "      <td>0.185517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Precision    Recall  F1 score\n",
              "basophil       0.101299  0.054242  0.070652\n",
              "eosinophil     0.196958  0.136029  0.160920\n",
              "erythroblast   0.082589  0.201745  0.117200\n",
              "ig             0.157617  0.173233  0.165057\n",
              "lymphocyte     0.093240  0.110497  0.101138\n",
              "monocyte       0.095928  0.163915  0.121027\n",
              "neutrophil     0.212418  0.064484  0.098935\n",
              "platelet       0.179453  0.192006  0.185517"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL_repyo285r"
      },
      "source": [
        "### Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHKClyJ63GOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "e38d8747-95a3-4d9b-97cf-acfe96c459ae"
      },
      "source": [
        "calculate_error(model, data, 'valid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total cost on  valid  data is  2.2302133645028017\n",
            "The Classification Accuracy on  valid  data is  16.530134581626683\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>basophil</th>\n",
              "      <th>eosinophil</th>\n",
              "      <th>erythroblast</th>\n",
              "      <th>ig</th>\n",
              "      <th>lymphocyte</th>\n",
              "      <th>monocyte</th>\n",
              "      <th>neutrophil</th>\n",
              "      <th>platelet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>basophil</th>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eosinophil</th>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>erythroblast</th>\n",
              "      <td>33.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>83.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>37.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lymphocyte</th>\n",
              "      <td>10.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monocyte</th>\n",
              "      <td>17.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutrophil</th>\n",
              "      <td>105.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>302.0</td>\n",
              "      <td>192.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelet</th>\n",
              "      <td>7.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>47.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              basophil  eosinophil  ...  neutrophil  platelet\n",
              "basophil          30.0        97.0  ...        80.0      70.0\n",
              "eosinophil        20.0        24.0  ...        31.0      28.0\n",
              "erythroblast      33.0       106.0  ...       105.0      83.0\n",
              "ig                37.0        79.0  ...        69.0      54.0\n",
              "lymphocyte        10.0        12.0  ...        13.0       6.0\n",
              "monocyte          17.0        76.0  ...        87.0      30.0\n",
              "neutrophil       105.0       259.0  ...       302.0     192.0\n",
              "platelet           7.0        16.0  ...        10.0      47.0\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>basophil</th>\n",
              "      <td>0.061728</td>\n",
              "      <td>0.115830</td>\n",
              "      <td>0.080537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eosinophil</th>\n",
              "      <td>0.134831</td>\n",
              "      <td>0.035874</td>\n",
              "      <td>0.056671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>erythroblast</th>\n",
              "      <td>0.085034</td>\n",
              "      <td>0.163934</td>\n",
              "      <td>0.111982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>0.190476</td>\n",
              "      <td>0.125413</td>\n",
              "      <td>0.151244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lymphocyte</th>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.037383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monocyte</th>\n",
              "      <td>0.086207</td>\n",
              "      <td>0.102740</td>\n",
              "      <td>0.093750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutrophil</th>\n",
              "      <td>0.218682</td>\n",
              "      <td>0.433286</td>\n",
              "      <td>0.290664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelet</th>\n",
              "      <td>0.364341</td>\n",
              "      <td>0.092157</td>\n",
              "      <td>0.147105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Precision    Recall  F1 score\n",
              "basophil       0.061728  0.115830  0.080537\n",
              "eosinophil     0.134831  0.035874  0.056671\n",
              "erythroblast   0.085034  0.163934  0.111982\n",
              "ig             0.190476  0.125413  0.151244\n",
              "lymphocyte     0.080000  0.024390  0.037383\n",
              "monocyte       0.086207  0.102740  0.093750\n",
              "neutrophil     0.218682  0.433286  0.290664\n",
              "platelet       0.364341  0.092157  0.147105"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqBC-AU72_79"
      },
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdM-ev0C3HBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "outputId": "d5b01288-386b-4326-bc8a-858c007b6dd2"
      },
      "source": [
        "calculate_error(model, data, 'test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total cost on  test  data is  2.2272426677608013\n",
            "The Classification Accuracy on  test  data is  11.085112606025154\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>basophil</th>\n",
              "      <th>eosinophil</th>\n",
              "      <th>erythroblast</th>\n",
              "      <th>ig</th>\n",
              "      <th>lymphocyte</th>\n",
              "      <th>monocyte</th>\n",
              "      <th>neutrophil</th>\n",
              "      <th>platelet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>basophil</th>\n",
              "      <td>58.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>95.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eosinophil</th>\n",
              "      <td>24.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>erythroblast</th>\n",
              "      <td>107.0</td>\n",
              "      <td>321.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>287.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>216.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>17.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lymphocyte</th>\n",
              "      <td>27.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>66.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monocyte</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutrophil</th>\n",
              "      <td>25.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>29.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelet</th>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              basophil  eosinophil  ...  neutrophil  platelet\n",
              "basophil          58.0        94.0  ...        94.0      39.0\n",
              "eosinophil        24.0        60.0  ...        71.0      68.0\n",
              "erythroblast     107.0       321.0  ...       306.0     216.0\n",
              "ig                17.0        57.0  ...        62.0      70.0\n",
              "lymphocyte        27.0        72.0  ...       102.0      66.0\n",
              "monocyte           0.0         0.0  ...         1.0       4.0\n",
              "neutrophil        25.0        54.0  ...        52.0      29.0\n",
              "platelet           1.0        11.0  ...         9.0      18.0\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>basophil</th>\n",
              "      <td>0.118126</td>\n",
              "      <td>0.223938</td>\n",
              "      <td>0.154667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eosinophil</th>\n",
              "      <td>0.159151</td>\n",
              "      <td>0.089686</td>\n",
              "      <td>0.114723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>erythroblast</th>\n",
              "      <td>0.075202</td>\n",
              "      <td>0.396721</td>\n",
              "      <td>0.126437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ig</th>\n",
              "      <td>0.118211</td>\n",
              "      <td>0.061056</td>\n",
              "      <td>0.080522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lymphocyte</th>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.134146</td>\n",
              "      <td>0.096210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monocyte</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutrophil</th>\n",
              "      <td>0.183099</td>\n",
              "      <td>0.074605</td>\n",
              "      <td>0.106014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelet</th>\n",
              "      <td>0.276923</td>\n",
              "      <td>0.035294</td>\n",
              "      <td>0.062609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Precision    Recall  F1 score\n",
              "basophil       0.118126  0.223938  0.154667\n",
              "eosinophil     0.159151  0.089686  0.114723\n",
              "erythroblast   0.075202  0.396721  0.126437\n",
              "ig             0.118211  0.061056  0.080522\n",
              "lymphocyte     0.075000  0.134146  0.096210\n",
              "monocyte       0.000000  0.000000       NaN\n",
              "neutrophil     0.183099  0.074605  0.106014\n",
              "platelet       0.276923  0.035294  0.062609"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}